PHP二十一问：PHP的垃圾回收机制
PHP 是一门托管型语言，在 PHP 编程中，程序员不需要手工处理内存资源的分配与释放（使用 C 编写 PHP 或 Zend 扩展除外），这就意味着 PHP 本身实现了垃圾回收机制（Garbage Collection）。在 PHP 官方网站可以看到对垃圾回收机制的介绍。

PHP的引用计数

PHP在内核中是通过zval这个结构体来存储变量的，在Zend/zend.h文件中找到了其定义：

PHP5 中定义如下：

struct _zval_struct {
        /* Variable information */
        zvalue_value value;             /* value */
        zend_uint refcount;
        zend_uchar type;        /* active type */
        zend_uchar is_ref;
};
而到了PHP7中定义如下：

struct _zval_struct {
    union {
        zend_long         lval;             /* long value */
        double            dval;             /* double value */
        zend_refcounted  *counted;
        zend_string      *str;
        zend_array       *arr;
        zend_object      *obj;
        zend_resource    *res;
        zend_reference   *ref;
        zend_ast_ref     *ast;
        zval             *zv;
        void             *ptr;
        zend_class_entry *ce;
        zend_function    *func;
        struct {
            uint32_t w1;
            uint32_t w2;
        } ww;
    } value;
    union {
        struct {
            ZEND_ENDIAN_LOHI_4(
                zend_uchar    type,         /* active type */
                zend_uchar    type_flags,
                zend_uchar    const_flags,
                zend_uchar    reserved)     /* call info for EX(This) */
        } v;
        uint32_t type_info;
    } u1;
    union {
        uint32_t     var_flags;
        uint32_t     next;                 /* hash collision chain */
        uint32_t     cache_slot;           /* literal cache slot */
        uint32_t     lineno;               /* line number (for ast nodes) */
        uint32_t     num_args;             /* arguments number for EX(This) */
        uint32_t     fe_pos;               /* foreach position */
        uint32_t     fe_iter_idx;          /* foreach iterator index */
    } u2;
};
我们定义一个PHP变量如下：

 $var = "mindoc";
 $var_dup = $var;
 unset($var);
第一行代码创建了一个字符串变量，申请了一个大小为9字节的内存，保存了字符串”laruence”和一个NULL(\0)的结尾。
第二行定义了一个新的字符串变量，并将变量var的值”复制”给这个新的变量。
第三行unset了变量var
这样的代码在我们平时的脚本中是很常见的，如果PHP对于每一个变量赋值都重新分配内存，copy数据的话，那么上面的这段代码公要申请18个字节的内存空间，而我们也很容易的看出来，上面的代码其实根本没有必要申请俩份空间，PHP的开发者也看出来了：

PHP中的变量是用一个存储在symbol_table中的符号名，对应一个zval来实现的，比如对于上面的第一行代码，会在symbol_table中存储一个值”var”, 对应的有一个指针指向一个zval结构，变量值”laruence”保存在这个zval中，所以不难想象，对于上面的代码来说，我们完全可以让”var”和”var_dup”对应的指针都指向同一个zval就可以了。

PHP也是这样做的，这个时候就需要介绍过zval结构中的refcount字段了。

refcount,顾名思义，记录了当前的zval被引用的计数。

不准确但却通俗的说：
refcount：多少个变量是一样的用了相同的值，这个数值就是多少。
is_ref：bool类型，当refcount大于2的时候，其中一个变量用了地址&的形式进行赋值，好了，它就变成1了。

在 PHP 中可以通过 xdebug 扩展中提供的方法来查看变量的计数变化：

1.第一步：查看内部结构

$name = "咖啡色的羊驼";
 xdebug_debug_zval('name');
会得到：

name:(refcount=1, is_ref=0),string '咖啡色的羊驼' (length=18)
2.第二步：增加一个计数

$name = "咖啡色的羊驼";
$temp_name = $name;
xdebug_debug_zval('name');
会得到：

name:(refcount=2, is_ref=0),string '咖啡色的羊驼' (length=18)
看到了吧，refcount＋1了。

3.第三步：引用赋值

$name = "咖啡色的羊驼";
$temp_name = &$name;
xdebug_debug_zval('name');
会得到：

name:(refcount=2, is_ref=1),string '咖啡色的羊驼' (length=18)
是的引用赋值会导致zval通过is_ref来标记是否存在引用的情况。

4.第四步：数组型的变量

    $name = ['a'=>'咖啡色', 'b'=>'的羊驼'];
    xdebug_debug_zval('name');
会得到：

name:
(refcount=1, is_ref=0),
array (size=2)
  'a' => (refcount=1, is_ref=0),string '咖啡色' (length=9)
  'b' => (refcount=1, is_ref=0),string '的羊驼' (length=9)
还挺好理解的，对于数组来看是一个整体，对于内部kv来看又是分别独立的整体，各自都维护着一套zval的refount和is_ref。

5.第五步：销毁变量

$name = "咖啡色的羊驼";
$temp_name = $name;
xdebug_debug_zval('name');
unset($temp_name);
xdebug_debug_zval('name');
会得到：

name:(refcount=2, is_ref=0),string '咖啡色的羊驼' (length=18)
name:(refcount=1, is_ref=0),string '咖啡色的羊驼' (length=18)
refcount计数减1，说明unset并非一定会释放内存，当有两个变量指向的时候，并非会释放变量占用的内存，只是refcount减1.

更多关于引用计数的请参考： http://www.laruence.com/2008/09/19/520.html

php的内存管理机制

知道了zval是怎么一回事，接下来看看如何通过php直观看到内存管理的机制是怎么样的。

外在的内存变化

先来一段代码：

//获取内存方法，加上true返回实际内存，不加则返回表现内存
var_dump(memory_get_usage());
$name = "咖啡色的羊驼";
var_dump(memory_get_usage());
unset($name);
var_dump(memory_get_usage());
会得到：

int 1593248
int 1593384
int 1593248
大致过程：定义变量->内存增加->清除变量->内存恢复

潜在的内存变化

当执行：

$name = "咖啡色的羊驼";
时候，内存的分配做了两件事情：

为变量名分配内存，存入符号表
为变量值分配内存
再来看代码：

var_dump(memory_get_usage());
for($i=0;$i<100;$i++)
{
    $a = "test".$i;
    $$a = "hello";    
}
var_dump(memory_get_usage());
for($i=0;$i<100;$i++)
{
    $a = "test".$i;
    unset($$a);    
}
var_dump(memory_get_usage());
会得到：

int 1596864
int 1612080
int 1597680
怎么和之前看的不一样？内存没有全部回收回来。

对于php的核心结构Hashtable来说，由于未知性，定义的时候不可能一次性分配足够多的内存块。所以初始化的时候只会分配一小块，等不够的时候在进行扩容，而Hashtable只扩容不减少，所以就出现了上述的情况:当存入100个变量的时候，符号表不够用了就进行一次扩容，当unset的时候只释放了”为变量值分配内存”，而“为变量名分配内存”是在符号表的，符号表并没有缩小，所以没收回来的内存是被符号表占去了。

潜在的内存申请与释放设计

php和c语言一样，也是需要进行申请内存的，只不过这些操作作者都封装到底层了，php使用者无感知而已。

首先我们要打破一个思维: PHP不像C语言那样, 只有你显示的调用内存分配相关API才会有内存的分配。也就是说, 在PHP中, 有很多我们看不到的内存分配过程。

比如对于:

$a = "laruence";
隐式的内存分配点就有:

为变量名分配内存, 存入符号表
为变量值分配内存
所以, 不能只看表象.

别怀疑,PHP的unset确实会释放内存(当然, 还要结合引用和计数), 但这个释放不是C编程意义上的释放, 不是交回给OS，对于PHP来说, 它自身提供了一套和C语言对内存分配相似的内存管理API:

emalloc(size_t size);
efree(void *ptr);
ecalloc(size_t nmemb, size_t size);
erealloc(void *ptr, size_t size);
estrdup(const char *s);
estrndup(const char *s, unsigned int length);
这些API和C的API意义对应， 在PHP内部都是通过这些API来管理内存的。

当我们调用emalloc申请内存的时候，PHP并不是简单的向OS要内存， 而是会像OS要一个大块的内存, 然后把其中的一块分配给申请者，这样当再有逻辑来申请内存的时候， 就不再需要向OS申请内存了， 避免了频繁的系统调用。

比如如下的例子:

var_dump(memory_get_usage(TRUE)); //注意获取的是real_size
$a = "laruence";
var_dump(memory_get_usage(TRUE));
unset($a);
var_dump(memory_get_usage(TRUE));
输出:

int(262144)
int(262144)
int(262144)
也就是我们在定义变量$a的时候, PHP并没有向系统申请新内存.

同样的, 在我们调用efree释放内存的时候, PHP也不会把内存还给OS, 而会把这块内存, 归入自己维护的空闲内存列表. 而对于小块内存来说, 更可能的是, 把它放到内存缓存列表中去(后记, 某些版本的PHP, 比如我验证过的PHP5.2.4, 5.2.6, 5.2.8, 在调用get_memory_usage()的时候, 不会减去内存缓存列表中的可用内存块大小, 导致看起来, unset以后内存不变).

php中垃圾是如何定义的？

首先我们需要定义一下“垃圾”的概念，GC负责清理的垃圾是指变量的容器zval还存在，但是又没有任何变量名指向此zval。因此GC判断是否为垃圾的一个重要标准是有没有变量名指向变量容器zval。

假设我们有一段PHP代码，使用了一个临时变量$tmp存储了一个字符串，在处理完字符串之后，就不需要这个$tmp变量了，$tmp变量对于我们来说可以算是一个“垃圾”了，但是对于GC来说，$tmp其实并不是一个垃圾，$tmp变量对我们没有意义，但是这个变量实际还存在，$tmp符号依然指向它所对应的zval，GC会认为PHP代码中可能还会使用到此变量，所以不会将其定义为垃圾。

那么如果我们在PHP代码中使用完$tmp后，调用unset删除这个变量，那么$tmp是不是就成为一个垃圾了呢。很可惜，GC仍然不认为$tmp是一个垃圾，因为$tmp在unset之后，refcount减少1变成了0(这里假设没有别的变量和$tmp指向相同的zval),这个时候GC会直接将$tmp对应的zval的内存空间释放，$tmp和其对应的zval就根本不存在了。此时的$tmp也不是新的GC所要对付的那种“垃圾”。那么新的GC究竟要对付什么样的垃圾呢，下面我们将生产一个这样的垃圾。

PHP5.3 之前的内存泄漏的垃圾回收

产生内存泄漏主要真凶：环形引用。 现在来造一个环形引用的场景：

$a = ['one'];
$a[] = &$a;
xdebug_debug_zval('a');
得到：

a:
(refcount=2, is_ref=1),
array (size=2)
  0 => (refcount=1, is_ref=0),string 'one' (length=3)
  1 => (refcount=2, is_ref=1),
        &array<
这样 $a数组就有了两个元素，一个索引为0，值为one字符串，另一个索引为1，为$a自身的引用。



此时删掉$a:

$a = ['one'];
$a[] = &$a;
unset($a);
PHP 5.3之后的垃圾内存回收

PHP5.3 的垃圾回收算法仍然以引用计数为基础，但是不再是使用简单计数作为回收准则，而是使用了一种同步回收算法，这个算法由IBM的工程师在论文Concurrent Cycle Collection in Reference Counted Systems中提出。

这个算法比较复杂，在这里，只能大体描述一下此算法的基本思想：

首先 PHP 会分配一个固定大小的“根缓冲区”，这个缓冲区用于存放固定数量的 zval（默认是10,000），如果需要修改则需要修改源代码 Zend/zend_gc.c 中的常量 GC_ROOT_BUFFER_MAX_ENTRIES 然后重新编译。

这个根缓冲区中存放的是“可能根（possible roots）”，就是可能发生内存泄露的 zval。当根缓冲区满了的时候（或者调用 gc_collect_cycle() 函数时），PHP 就会执行垃圾回收。

可能根我个人理解就是循环引用的数组和对象，我觉得判决一个 zval 是不是可能根也是这个算法的关键，但是没有找到相应的资料。

回收算法步骤如下：



步骤 A 把所有可能根（possible roots 都是 zval 变量容器），放在根缓冲区（root buffer）中（称为疑似垃圾)，并确保每个可能的垃圾根（possible garbage root）在缓冲区中只出现一次。只有在根缓冲区满了的时候，才对缓冲区内部所有不同的变量容器执行垃圾回收操作；

步骤 B 被称为模拟删除，对每个根缓冲区中的根 zval 按照深度优先遍历算法遍历所有能遍历到的 zval，并将对应的 refcount 减 1，同时为了避免对同一 zval 多次减 1（因为可能不同的根能遍历到同一个 zval），每次对某个 zval 减 1 后就对其标记为“已减”。需要强调的是，这个步骤中，起初节点 zval 本身不做减 1 操作，但是如果节点 zval 中包含的符号表中有节点又指向了初始的 zval（环形引用），那么这个时候需要对节点 zval 进行减 1 操作；

步骤 C 被称为模拟恢复，基本就是步骤 B 的逆运算，但恢复是有条件的。再次对每个缓冲区中的 zval 做深度优先遍历，如果某个 zval 的 refcount 不为 0，则对其加 1，否则保持其为 0。同样每个变量只能恢复一次；

步骤 D 清空根缓冲区中的所有根（注意是把所有 zval 从缓冲区中清除而不是销毁它们），然后销毁所有 refcount 为 0 的 zval，并收回其内存，是真实删除的过程。

这个道理其实很简单，假设数组 a 的 refcount 等于 m，a 中有 n 个元素又指向 a，如果 m == n，那么判断 m - n = 0，那么 a 就是垃圾，如果 m > n，那么算法的结果 m - n > 0，所以 a 就不是垃圾了。

m = n 代表什么？ 代表 a 的 refcount 都来自数组 a 自身包含的 zval 元素，说明 a 之外没有任何变量指向它，说明 a 被 unset 掉了，用户代码空间中无法再访问到 a 所对应的 zval，也就是代表 a 是泄漏的内存，因此 GC 应该回收 a 所对应的 zval。

举例如下：

$a = ['one']; --- zval_a（将$a对应的zval，命名为zval_a）
$a[] = &$a; --- step1
unset($a);  --- step2
为进行unset之前(step1)，进行算法计算，对这个数组中的所有元素（索引0和索引1）的zval的refcount进行减1操作，由于索引1对应的就是zval_a，所以这个时候zval_a的refcount应该变成了1，这样说明zval_a不是一个垃圾不进行回收。

当执行unset的时候(step2)，进行算法计算，由于环形引用，上文得出会有垃圾的结构体，zval_a的refcount是1(zval_a中的索引1指向zval_a)，用算法对数组中的所有元素（索引0和索引1）的zval的refcount进行减1操作，这样zval_a的refcount就会变成0，于是就认为zval_a是一个需要回收的垃圾。

算法总的套路:对于一个包含环形引用的数组，对数组中包含的每个元素的zval进行减1操作，之后如果发现数组自身的zval的refcount变成了0，那么可以判断这个数组是一个垃圾。

简言之，PHP5.3 的垃圾回收算法有以下几点特性：

并不是每次 refcount 减少时都进入回收周期，只有根缓冲区满额后在开始垃圾回收；
解决了循环引用导致的内存泄露问题；
整体上可以总将内存泄露保持在一个阈值以下（与缓冲区的大小有关）。
PHP5.3之前和之后垃圾回收算法的性能比较

内存占用空间

分别在 PHP5.2 和 PH5.3环境下执行下面的脚本，并记录内存占用情况（其中排除了脚本启动时 PHP 本身占用的基本内存）：

class Foo
{
    public $var = '3.1415962654';
}

$baseMemory = memory_get_usage();

for ( $i = 0; $i <= 100000; $i++ )
{
    $a = new Foo;
    $a->self = $a;
    if ( $i % 500 === 0 )
    {
        echo sprintf( '%8d: ', $i ), memory_get_usage() - $baseMemory, "\n";
    }
}
这是个经典的内存泄露例子，创建一个对象，这个对象中的一个属性被设置为对象本身。在下一个循环（iteration）中，当脚本中的变量被重新赋值时，就会发生内存泄漏。

比较结果如下：



从这个图表中，可以看出 PHP5.3 的最大内存占用大概是 9Mb，而 PHP5.2 的内存占用一直增加。在 5.3 中，每当循环 10,000 次后（共产生 10,000 个可能根），根缓冲区满了，就会执行垃圾回收机制，并且释放那些关联的可能根的内存。所以 PHP5.3 的内存占用图是锯齿型的。

执行时间

为了检验执行时间，稍微修改上面的脚本，循环更多次并且删除了内存占用的计算，脚本代码如下：

class Foo
{
    public $var = '3.1415962654';
}

for ( $i = 0; $i <= 1000000; $i++ )
{
    $a = new Foo;
    $a->self = $a;
}

echo memory_get_peak_usage(), "\n";
分别在打开/关闭垃圾回收机制（通过配置 zend.enable_gc实现）的情况下运行脚本，并记录时间。

time php -dzend.enable_gc=0 -dmemory_limit=-1 -n example2.php
time php -dzend.enable_gc=1 -dmemory_limit=-1 -n example2.php
第一个命令持续执行时间大概为 10.7 秒，而第二个命令耗费 11.4 秒。时间上增加了 7%。然而，内存的占用峰值降低了 98%，从 931Mb 降到了 10Mb。

这个测试并不能代表真实应用程序的情况，但是它的确显示了新的垃圾回收机制在内存占用方面的好处。而且在执行中出现更多的循环引用变量时，内存节省会更多，但时间增加的百分比都是 7% 左右。

PHP垃圾回收的相关配置

可以通过修改配置文件 php.ini 中的 zend.enable_gc 来打开或关闭 PHP 的垃圾回收机制，也可以通过调用 gc_enable() 或 gc_disable() 打开或关闭 PHP 的垃圾回收机制。

在 PHP5.3 中即使关闭了垃圾回收机制，PHP 仍然会记录可能根到根缓冲区，只是当根缓冲区满额时，不会自动运行垃圾回收，当然，任何时候您都可以通过手工调用 gc_collect_cycles() 函数强制执行内存回收。

参考：

一看就懂系列之 由浅入深聊一聊php的垃圾回收机制:
PHP的垃圾回收机制
深入理解PHP内存管理之谁动了我的内存
深入理解PHP原理之变量分离/引用(Variables Separation)
第 2 页（共 13 页）
在PHP7中主要通过以下四点来提升性能：

存储变量的结构体变小，尽量使结构体里成员共用内存空间，减少引用，这样内存占用降低，变量的操作速度得到提升

字符串结构体的改变，字符串信息和数据本身原来是分成两个独立内存块存放，php7尽量将它们存入同一块内存，提升了cpu缓存命中率

数组结构的改变，数组元素和hash映射表在php5中会存入多个内存块，php7尽量将它们分配在同一块内存里，降低了内存占用、提升了cpu缓存命中率

改进了函数的调用机制，通过对参数传递环节的优化，减少一些指令操作，提高了执行效

PHP7 中储存结构体变化

struct _zval_struct {
    zend_value value;
    union {
        struct {
            ZEND_ENDIAN_LOHI_4(
                zend_uchar type,
                zend_uchar type_flags,
                zend_uchar const_flags,
                zend_uchar reserved
            )
        } v;
        uint32_t type_info;
    } u1;
    union {
        uint32_t var_flags;
        uint32_t next;       /* hash collision chain */
        uint32_t cache_slot; /* literal cache slot */
        uint32_t lineno;     /* line number (for ast nodes) */
    } u2;
};
你可以完全不用注意这个结构的定义中的ZEND_ENDIAN_LOHI_4这个宏，它仅仅只是用于表示拥有不同的字节序的机器中的可预测的内存布局情况。

zval结构有三个部分：第一部分是value。zend_value联合体有8个字节，它可以保存任何类型的值，包括整数、字符串、数组等。具体保存什么取决于zval的类型。

第二个部分是4字节的type_info，它包含变量的真正类型（类似于IS_STRING、IS_ARRAY），以及一系列的标志位，用于提供跟类型相关的信息。例如，如果zval保存的是一个对象，那么这些类型标志位会说明它是一个非常量（non-constant）、可引用计数（refcounted）、可垃圾回收（garbage-collectible）、不可复制（non-copying）的类型。

最后一部分占有4个字节，通常情况下不会被用到（它只是用于填充内存，如果不存在的话，编译器也会自动实现）（对于这一点完全不了解的同学，可以自行搜索内存对齐）。然而，在某些特殊情况下，这些空间也会被用于存放一些额外的信息。例如，AST（抽象语法树）的节点使用它来存放行号，VM（虚拟机）常量使用它来存放缓冲槽的索引，以及Hashtable使用它来保存冲突处理链上的下一个元素——这一部分才是我们要重点关注的。

新的zval的实现跟老的比较，最大的一点差别是：没有refcount字段。这是因为新的zval将不会被单独分配，它会被直接嵌入到任何需要存放它的地方（例如，一个hashtable bucket中）。

所以zvals将不再需要使用引用计数（refcounting），复杂数据类型例如字符串、数组、对象和资源（resources）仍需要使用。所以新的zval的设计将引用计数（包括跟垃圾回收相关的信息）从zval转移到了数组/对象/等中。这种方式有很多优点，在此列出几点：

保存简单的值（例如，boolean、integer或者float）的zval将不再需要额外分配内存。所以避免内存分配的头部冗余（allocation header overhead），以及减少不必要的内存分配和内存释放，可以提高缓存的局部性，从而提高性能。
保存简单的值的zval不需要保存refcount和GC的根缓冲区。
避免两次引用计数。例如，以前的对象即使用了zval的引用计数，又使用额外的对象的引用计数，对于支持按对象传递的语义而言，这是必须的。
现在所有的复杂的值都内嵌一个引用计数，它们可以不依赖于zval的机制而进行共享。特别是字符串现在也有可能共享。这对于hashtable的实现也很重要，因为这样就不用再拷贝非interned字符串的键了。
内部类型zend_string

Zend_string是实际存储字符串的结构体，实际的内容会存储在val（char，字符型）中，而val是一个char数组，长度为1（方便成员变量占位）。



结构体最后一个成员变量采用char数组，而不是使用char*，这里有一个小优化技巧，可以降低CPU的cache miss。

如果使用char数组，当malloc申请上述结构体内存，是申请在同一片区域的，通常是长度是sizeof(_zend_string) + 实际char存储空间。但是，如果使用char*，那个这个位置存储的只是一个指针，真实的存储又在另外一片独立的内存区域内。

使用char[1]和char*的内存分配对比：



从逻辑实现的角度来看，两者其实也没有多大区别，效果很类似。而实际上，当这些内存块被载入到CPU的中，就显得非常不一样。前者因为是连续分配在一起的同一块内存，在CPU读取时，通常都可以一同获得（因为会在同一级缓存中）。而后者，因为是两块内存的数据，CPU读取第一块内存的时候，很可能第二块内存数据不在同一级缓存中，使CPU不得不往L2（二级缓存）以下寻找，甚至到内存区域查到想要的第二块内存数据。这里就会引起CPU Cache Miss，而两者的耗时最高可以相差100倍。

另外，在字符串复制的时候，采用引用赋值，zend_string可以避免的内存拷贝。

HashTable 的内存占用

首先让我们总结一下为什么新的实现方式占用的内存更少。先申明下，这里我只会使用64位系统中的数字，而且只考虑每个元素的大小，而忽略Hashtable结构体。

在PHP 5.x中，一个元素需要占用144个字节（很恐怖）。在PHP 7中这个大小下降到36个字节，在packed情况下只需要32个字节。下面是内存变化的详细情况：

Zvals不再单独分配，所以这节省了16个字节的内存分配冗余。
Buckets也不用再单独分配，所以又节省了16个字节的内存分配冗余。
对于简单类型的值，zval本身就少了16个字节。
保持数组顺序不再需要16个字节用于维持双向链表的链接指针，而且这个顺序是隐式的。
冲突处理链表现在是单链表，这又节省了8个字节。更进一步来看，现在用的是一个索引列表，并且每个索引是嵌入到zval中的，所以这又节省了8个字节。
zval是嵌入到bucket中的，没必要再保存一个指向它的指针。如果分析老版本的实现细节的话，我们实际上节省了2个指针，这就又是16个字节了。
键的长度不用再保存在bucket中，又是8个字节。不过，如果键是一个字符串，而不是一个整数的话，它的长度还是需要保存在zend_string结构体中。这种情况下，对内存的影响不可能精确估算，因为zend_string结构体是共享的，这意味着之前的hashtable需要拷贝字符串，如果这个字符串不是interned的话（这一条没怎么看清楚）。
包含冲突列表头部的数组现在是基于索引的，这样每个元素又节省了4个字节。对于packed数组，这个数组根本就不需要，又节省了4个字节。
首先申明一下，上面的总结只是为了说明PHP 7中的新的Hashtable实现在多个方面都比老版本的要好。首先，新Hashtable的实现使用了更多的内嵌结构体（相对于单独分配内存而言）。这会有什么不利的影响呢？

如果你看下文章开头的示例，你会发现在64位系统下，PHP 7中一个含有100000个元素的数组会占用4.00MB的内存。在这个示例中，我们处理的是packed数组，所以我们实际需要的内存使用量是32 * 100000 = 3.05MB。这个差别是因为所有分配的内存的大小都是2的幂次方，所以包含100000个元素数组，nTableSize的大小将是2^17=131072，所以最终分配的内存就是32 * 131072（4MB）。

当然老的Hashtable的实现中分配的内存的大小也必须是2的幂次方。不过它只会分配一个包含bucket指针的数组（每个指针占8个字节），其他的所有东西都是根据具体需求来分配。所以在PHP 7中，我们多分配了3231072(0.95MB)的未使用内存，而在PHP 5.x中只浪费了`831072(0.24MB)`的内存。

另外一种需要考虑的情况是，如果数组中所保存元素的值并非都不同，这又会有什么不同？简单起见，我们考察下数组中所有元素的值都相同的情况。所以将第一个示例中的函数range替换为array_fill：

$startMemory = memory_get_usage();
$array = array_fill(0, 100000, 42);
echo memory_get_usage() - $startMemory, " bytes\n";
最终运行的结果为：

32 bit	64 bit
PHP 5.6	4.70 MiB	9.39 MiB
PHP 7.0	3.00 MiB	4.00 MiB
从这个结果可以看到PHP 7中内存的占用量没有变，每个元素都独自使用一个zval，这样也没有变的理由。不过PHP 5.x中的内存占用量就降低了不少，这是因为只有一个zval用于表示所有的值。尽管如此，PHP 7的内存占用量还是要由于PHP 5.x，虽然差别已经小了一些。

当键为字符串（可能是共享的或者是interned）或者为复杂值的时候，事情就会变得更复杂。当然不管怎样，在这些情况下，最终PHP 7所占用的内存都远小于PHP 5.x，也许上面所列出的数据在某些情况下有些乐观了。

通过宏定义和内联函数（inline），让编译器提前完成部分工作

C语言的宏定义会被在预处理阶段（编译阶段）执行，提前将部分工作完成，无需在程序运行时分配内存，能够实现类似函数的功能，却没有函数调用的压栈、弹栈开销，效率会比较高。内联函数也类似，在预处理阶段，将程序中的函数替换为函数体，真实运行的程序执行到这里，就不会产生函数调用的开销。

PHP7在这方面做了不少的优化，将不少需要在运行阶段要执行的工作，放到了编译阶段。例如参数类型的判断（Parameters Parsing），因为这里涉及的都是固定的字符常量，因此，可以放到到编译阶段来完成，进而提升后续的执行效率。

例如下图中处理传递参数类型的方式，从左边的写法，优化为右边宏的写法。



抽象树语法

PHP是一种解释性语言，通过解析器来执行。

那么首先来看一下编译器与解释器的区别：读入源语言后，解释器和编译器都要进行词法分析、语法分析和语义分析，之后，二者开始有所分别。

解析器与编译器的区别：

解释器在语义分析后选择了直接执行语句；
编译器在语义分析后选择将将语义存储成某一种中间语言，之后通过不同的后端翻译成不同的机器语言（可执行程序）。其存在一个预编译的过程。如下图所示：


PHP7之前的版本，代码解释过程：

PHP代码在语法解析阶段直接生成ZendVM指令，即在zend_language_parser.y中直接生成opline指令，使得编译器与执行器耦合在一起。

编译生成的指令再供执行引擎使用，该指令是在语法指令直接生成的，若要更换执行引擎，怎需要修改语法解析规则；若PHP语法变化，但没有修改执行引擎，仍需要修改语法解析规则。其代码解析过程如下图：



PHP7的代码解析过程：



Native TLS

PHP5.x版本扩展中，有TSRM_CC、TSRM_DC宏，用于线程安全。

PHP中有很多变量需要在不同函数间共享，多线程的环境下不能简单地通过全局变量来实现，为了适应线程的应用环境，PHP提供了一个线程安全资源管理器，将全局资源进行线程隔离，不同的线程之间互不干扰。

使用全局资源需要先获取本线程的资源池，这个过程比较占用时间，因此，PHP5.x通过参数传递的方式将本线程的资源池传递给其他函数，避免重复查找。这种方式需要所有函数接受资源池的参数（TSRM_DC宏所加的参数），这些参数传递不仅易遗漏参数，还是得代码不优雅。

PHP7使用Native TLS（线程局部存储）来保存线程的资源池，简单来说就是通过__thread标识一个全局变量，这样这个全局变量就是线程独享的了，不同线程的修改不会相互影响。

参考

PHP 7中新的Hashtable实现和性能改进
PHP7革新与性能优化
PHP7变量结构分析

第 3 页（共 13 页）
前言

随着服务器硬件迭代升级，配置也越来越高。为充分利用服务器资源，并发编程也变的越来越重要。在开始之前，需要了解一下并发(concurrency)和并行(parallesim)的区别。

并发: 逻辑上具有处理多个同时性任务的能力。
并行: 物理上同一时刻执行多个并发任务。
通常所说的并发编程，也就是说它允许多个任务同时执行，但实际上并不一定在同一时刻被执行。在单核处理器上，通过多线程共享CPU时间片串行执行(并发非并行)。而并行则依赖于多核处理器等物理资源，让多个任务可以实现并行执行(并发且并行)。

多线程或多进程是并行的基本条件，但单线程也可以用协程(coroutine)做到并发。简单将Goroutine归纳为协程并不合适，因为它运行时会创建多个线程来执行并发任务，且任务单元可被调度到其它线程执行。这更像是多线程和协程的结合体，能最大限度提升执行效率，发挥多核处理器能力。

Go编写一个并发编程程序很简单，只需要在函数之前使用一个Go关键字就可以实现并发编程。

func main() {    
    go func(){
        fmt.Println("Hello,World!")
    }()
}
为什么Go要实现自己调度器

POSIX线程API是对已有的UNIX进程模型的逻辑扩展，因此线程和进程在很多方面都类似。例如，线程有自己的信号掩码，CPU affinity（进程要在某个给定的 CPU 上尽量长时间地运行而不被迁移到其他处理器的倾向性），cgroups。但是有很多特性对于Go程序来说都是累赘。

另外一个问题是基于Go语言模型，OS的调度决定并不一定合理。例如，Go的垃圾回收需要内存处于一致性的状态，这需要所有运行的线程都停止。垃圾回收的时间点是不确定的，如果仅由OS来调度，将会由大量的线程停止工作。

单独开发一个Go的调度器能让我们知道什么时候内存处于一致性的状态。也就是说，当开始垃圾回收时，运行时只需要为当时正在CPU核上运行的那个线程等待即可，而不是等待所有的线程。

Go调度器组成

操作系统的调度模型是大致上有两种N:1和1:1.。N:1模型中用户态的线程运行在一个内核线程上，这种方式上下文切换快，但不能有效利用多核。

1:1模型中的一个用户态线程对应一个内核线程，这种方式有效利用了多核，但上下文切换非常慢(因为要不停 trap 陷入内核)。Goroutine是协程，即轻量级线程，用户态完成调度，Rob Pike先生想利用有限的os线程去调度和执行任意数量的goroutine，显然是想把N:1模型和1:1模型的优点都收入囊中。

1、 初级设想： 任务队列 + 线程

thread+queue

其中G就是goroutine，先开一个线程池，线程不停地从queue中取goroutine执行。如果一个goroutine里面出现了长时间系统调用，那么就会阻塞线程直到系统调用结束。

假设队列里面所有的goroutine都是长时间系统调用，那么线程都会被阻塞住，这显然不合理。我们需要的是：goroutine可以阻塞，但线程不可以阻塞或者说线程不可以出现长时间阻塞。要做到这点线程必须知道此时goroutine的状态，然后是wait状态的时候就将它换出去，执行其他goroutine，同时记住上次goroutine的上下文，以便下次继续执行。goroutine的状态：

goroutine-stauts

这样G的数据结构就很清楚了：

struct G  {
     uintptr    stackguard;    // 分段栈的可用空间下界
     uintptr    stackbase;    // 分段栈的栈基址
     Gobuf      sched;        //进程切换时，利用sched域来保存上下文
     uintptr    stack0;
     FuncVal*    fnstart;    // goroutine运行的函数
     void*    param;          // 用于传递参数，睡眠时其它goroutine设置param，唤醒时此goroutine可以获取
     int16    status;        // 状态Gidle,Grunnable,Grunning,Gsyscall,Gwaiting,Gdead
     int64    goid;          // goroutine的id号
     G*    schedlink;
     M*    m;      // for debuggers, but offset not hard-coded
     M*    lockedm;          // G被锁定只能在这个m上运行
     uintptr    gopc;        // 创建这个goroutine的go表达式的pc
};
其中status字段就表示goroutine的状态。有了这些信息，线程就可以自如地调度和执行协程了。这个方案是完美的吗? 至少我们能看出一个地方不好：线程每次取G的时候都要加排它锁，这样势必导致调度和执行的效率下降。我们把G分成多个queue，每一个queue都归属于一个线程去执行(M* lockedm)。这样线程只需要管理自己的queue队列就好了，不需要每次都竞争解决了。

2、中级设想：线程独享任务队列 + 线程 + 调度器

queues 

这样是不是完美了呢？牛人说过：计算机上的所有问题都可以通过增加一个抽象层来解决。我们希望线程不要过多的担负调度的任务，调度应该由抽象层来完成，线程只管执行，于是乎：

m-queues

M的数据结构出来了：

struct M   {
     G*    g0;        // 带有调度栈的goroutine
     G*    gsignal;    // signal-handling G 处理信号的goroutine
     void    (*mstartfn)(void);  // 线程入口
     G*    curg;        // M中当前运行的goroutine
    P*    p;        // 关联P以执行Go代码 (如果没有执行Go代码则P为nil)
    P*    nextp;
    int32    mallocing; //状态
    int32    helpgc;        //不为0表示此m在做帮忙gc。helpgc等于n只是一个编号
    M*    alllink;    // 这个域用于链接allm
    M*    schedlink;
     MCache    *mcache;
    G*    lockedg;
    M*    nextwaitm;    // next M waiting for lock
    GCStats    gcstats;
};
增加了一个M层来参与调度goroutine，这样让线程从调度和执行任务里面解脱出来。M是machine的缩写，是对机器的抽象，每个m都是对应到一条操作系统的物理线程。

3、终极进化：线程独享任务队列 + 线程 + 调度器 + 抢占式

假设一个情况：如果一个Goroutine一直占用CPU，长时间没有被调度过， 就会被runtime抢占掉，把CPU时间交给其他Goroutine。又需要一个抽象层来帮忙下了：

m-p-queues

P的数据结构出来了：

struct P  {
    Lock;
    uint32    status;  // Pidle或Prunning等
    P*    link;
    uint32    schedtick;  // 每次调度时将它加一
    M*    m;    // 链接到它关联的M (nil if idle)
    MCache*    mcache;
    G*    runq[256];
    int32    runqhead;
    int32    runqtail;
    G*    gfree;
};
P是Go1.1中新加入的一个数据结构，它是Processor的缩写。结构体P的加入是为了提高Go程序的并发度，实现更好的调度。M代表OS线程。P代表Go代码执行时需要的资源。当M执行Go代码时，它需要关联一个P，当M为idle或者在系统调用中时，它也需要P。有刚好GOMAXPROCS个P。所有的P被组织为一个数组，在P上实现了工作流窃取的调度器。

4、Golang 的终极BOSS：Sched

不考虑 g0 和 gsignal 的话，我们可以简单地认为调度就是将 m 绑定到 p，然后在 m 中不断循环执行调度函数(runtime.schedule)，寻找可用的 g 来执行，所以，P和M的现场是不用加锁的，但是如果多个P去操作全局的G队列，则需要加全局锁，而 Sched 就是全局调度器。

全局调度器只有一个：

type schedt struct {
    // 下面两个变量需以原子访问访问。保持在 struct 顶部，以使其在 32 位系统上可以对齐
    goidgen  uint64
    lastpoll uint64

    lock mutex

    // 当修改 nmidle，nmidlelocked，nmsys，nmfreed 这些数值时
    // 需要记得调用 checkdead

    midle        muintptr // idle m's waiting for work
    nmidle       int32    // 当前等待工作的空闲 m 计数
    nmidlelocked int32    // 当前等待工作的被 lock 的 m 计数
    mnext        int64    // 当前预缴创建的 m 数，并且该值会作为下一个创建的 m 的 ID
    maxmcount    int32    // 允许创建的最大的 m 数量
    nmsys        int32    // number of system m's not counted for deadlock
    nmfreed      int64    // cumulative number of freed m's

    ngsys uint32 // number of system goroutines; updated atomically

    pidle      puintptr // 空闲 p's
    npidle     uint32
    nmspinning uint32 // See "Worker thread parking/unparking" comment in proc.go.

    // 全局的可运行 g 队列
    runqhead guintptr
    runqtail guintptr
    runqsize int32

    // dead G 的全局缓存
    gflock       mutex
    gfreeStack   *g
    gfreeNoStack *g
    ngfree       int32

    // sudog 结构的集中缓存
    sudoglock  mutex
    sudogcache *sudog

    // 不同大小的可用的 defer struct 的集中缓存池
    deferlock mutex
    deferpool [5]*_defer

    // 被设置了 m.exited 标记之后的 m，这些 m 正在 freem 这个链表上等待被 free
    // 链表用 m.freelink 字段进行链接
    freem *m

    gcwaiting  uint32 // gc is waiting to run
    stopwait   int32
    stopnote   note
    sysmonwait uint32
    sysmonnote note

    // safepointFn should be called on each P at the next GC
    // safepoint if p.runSafePointFn is set.
    safePointFn   func(*p)
    safePointWait int32
    safePointNote note

    profilehz int32 // cpu profiling rate

    procresizetime int64 // 上次修改 gomaxprocs 的纳秒时间
    totaltime      int64 // ∫gomaxprocs dt up to procresizetime
}
调度流程图如下：

yes
no
no
yes
no
yes
schedule
schedtick%61 == 0
globrunqget
runqget
gp == nil
execute
gp == nil
findrunnable

Go调度器调度过程

首先创建一个G对象，G对象保存到P本地队列或者是全局队列。P此时去唤醒一个M。P继续执行它的执行序。M寻找是否有空闲的P，如果有则将该G对象移动到它本身。接下来M执行一个调度循环(调用G对象->执行->清理线程→继续找新的Goroutine执行)。

M执行过程中，随时会发生上下文切换。当发生上线文切换时，需要对执行现场进行保护，以便下次被调度执行时进行现场恢复。Go调度器M的栈保存在G对象上，只需要将M所需要的寄存器(SP、PC等)保存到G对象上就可以实现现场保护。当这些寄存器数据被保护起来，就随时可以做上下文切换了，在中断之前把现场保存起来。如果此时G任务还没有执行完，M可以将任务重新丢到P的任务队列，等待下一次被调度执行。当再次被调度执行时，M通过访问G的vdsoSP、vdsoPC寄存器进行现场恢复(从上次中断位置继续执行)。



1、P 队列

通过上图可以发现，P有两种队列：本地队列和全局队列。

本地队列： 当前P的队列，本地队列是Lock-Free，没有数据竞争问题，无需加锁处理，可以提升处理速度。

全局队列：全局队列为了保证多个P之间任务的平衡。所有M共享P全局队列，为保证数据竞争问题，需要加锁处理。相比本地队列处理速度要低于全局队列。

2、 G 的调度

在1.3版本以前，G的调度是非抢占式的，只要你的状态共享的代码块不跨越调度点或者IO调度点, 是不需要加锁的, 天然的无锁状态。1.3以后实现了类似抢占式的调度（编译器会在代码中插内容触发调度），上面的天然无锁状态也就不存在了。就算用GOMAXPROCS把最大并行数（P）设置为1, 也无法用无锁的模型玩耍了。

那么如果G中执行了带阻塞的系统调用，调度会有什么样的变化呢？如下图所示：



P转而在OS线程M1上运行，这样就不会因为一个阻塞调用，而阻塞了P上所有的G。图中的M1可能是被创建，或者从线程池中取出。当被丢弃的M0-G对完成系统调用变成可执行状态时，它必须尝试取得一个context P来运行goroutine，一般情况下，它会从其他的OS线程那里偷一个P过来，如果没有偷到的话，它就把goroutine放在一个global runqueue里，然后自己就去睡大觉了（回到线程池里）。Contexts们也会周期性的检查global runqueue，否则global runqueue上的goroutine永远无法执行。这也就是为什么即使GOMAXPROCS P被设置成1，Goroutine还是能用到多核处理。

当一个P对象将维护的runqueue里的G全部执行完之后，可以从别的P的runqueue底部拿到一半的G放入自己的runqueue中执行，这也就是为什么叫做Work stealing算法，这也是Goroutine为何高效的一个很大原因。如下图所示：



G比系统线程要简单许多，相对于在内核态进行上下文切换，G的切换代价低了很多，调度策略非常简单，毕竟操作系统要为各种复杂的场景提供完整的解决方案，而通常我们应用程序层面解决的问题都相对简单。

3、上线文切换

简单理解为当时的环境即可，环境可以包括当时程序状态以及变量状态。例如线程切换的时候在内核会发生上下文切换，这里的上下文就包括了当时寄存器的值，把寄存器的值保存起来，等下次该线程又得到cpu时间的时候再恢复寄存器的值，这样线程才能正确运行。

对于代码中某个值说，上下文是指这个值所在的局部(全局)作用域对象。相对于进程而言，上下文就是进程执行时的环境，具体来说就是各个变量和数据，包括所有的寄存器变量、进程打开的文件、内存(堆栈)信息等。

4、线程清理

Goroutine被调度执行必须保证P/M进行绑定，所以线程清理只需要将P释放就可以实现线程的清理。什么时候P会释放，保证其它G可以被执行。P被释放主要有两种情况。

主动释放：最典型的例子是，当执行G任务时有系统调用，当发生系统调用时M会处于Block状态。调度器会设置一个超时时间，当超时时会将P释放。

被动释放：如果发生系统调用，有一个专门监控程序，进行扫描当前处于阻塞的P/M组合。当超过系统程序设置的超时时间，会自动将P资源抢走。去执行队列的其它G任务。

5、 非阻塞IO与IO多路复用

现在我们知道协程的创建和上线文切换都非常“轻”，但是在进行带阻塞系统调用时执行体M会被阻塞，这就需要创建新的系统资源，而在高并发的web场景下如果使用阻塞的IO调用，网络IO大概率阻塞较长的时间，导致我们还是要创建大量的系统线程，所以Go需要尽量使用非阻塞的系统调用，虽然Go的标准库提供的是同步阻塞的IO模型，但底层其实是使用内核提供的非阻塞的IO模型。当Goroutine进行IO操作而数据未就绪时，syscall返回error，当前执行的Goroutine被置为阻塞态而M并没有被阻塞，P就可以继续使用当前执行体M继续执行下一个G，这样P就不需要再跑到别的M，从而也就不会去创建新的M。

当然只有非阻塞IO还不够，Go抽象了netpoller对象来进行IO多路复用，在linux下通过epoll来实现IO多路复用。当G由于IO未就绪而被置为阻塞态时，netpoller将对应的文件描述符注册到epoll实例中进行epoll_wait，就绪的文件描述符回调通知给阻塞的G，G更新为就绪状态等待调度继续执行，这种实现使得Golang在进行高并发的网络通信时变得非常强大，相比于php-fpm的多进程模型，Golang Http Server使用很少的线程资源运行非常多的Goroutine，而且尽可能的让每一个线程都忙碌起来，而不是阻塞在IO调用上，提高了CPU的利用率。

参考

Go并发编程-Goroutine如何调度的?
小小书童窥探goroutine调度
第 4 页（共 13 页）
为什么要要读 golang 的源码

大家都知道 golang 1.5 是一个里程碑版本，因为这个版本实现了 golang 的自举，也就是说 golang 整个语言的运行时用自己 golang 来实现了，除了少量的汇编语言，实现自举充分说明了 golang 的稳定性。所以我读 golang 的源码的源码不仅能够学习 golang 语言，还能学习到 google 的对 golang 的设计，学习 golang 能够将汇编，编译原理，链接，操作系统 这四个方面的知识连成一个整体，对自己本身系统知识的了解和熟悉也能有较大的提升。

golang 的精髓包含两个方面

golang 的内存管理和垃圾回收
golang 的协程序调度
golang 在语言层面就实现了协程的支持，这样能大大减轻程序员在并发编程上的心智负担。很好的驾驭了多核云时代。使用 golang 实现的明星项目就不少了，

容器相关docker，kubernetes
etcd/consul
数据库相关：influxdb，TiDB
区块链技术：fabric，chain
更加详细的信息可以戳 这里 基本上当前热门和有趣的项目大部分都是 golang 开发的，可以说我们正在经历一个基础设施有 c 到 golang 重写的过程中。

Golang 语言运行时有两个皇冠上的明珠，其一为内存管理和垃圾收集，内存管理是基于 google tcmalloc 算法实现的，其二就是 golang 的 goroutine 设计和调度。我们这次先分析 golang 的 goroutine 和调度器。

现代操作系统的调度

cpu 中一些基本的概念

我们先来看看现代计算机的一般结构

CPU调度

注意上图中的一些重要的组件

pc: 程序计数器，主要标示下一条指令的位置，同时注意 pc 不能通过普通命令如：mov 等来改变这个，只能通过 jmp, call/ret, int 这些命令来修改它
由于寄存器是有限的，当 cpu 完成指令时，需要的输入或者输出超出了寄存器的个数时，必需配合内存来工作，这时需要时使用栈标示寄存器
由于外设是通过 int 中断来和 cpu 通讯，或者程序内存错误如除 0 等，这些情况都会修改标志寄存器
线程（Thread）

系统内核态，更轻量的进程
由系统内核进行调度
同一进程的多个线程可共享资源
线程的出现解决了两个问题，一个是GUI出现后急切需要并发机制来保证用户界面的响应。第二是互联网发展后带来的多用户问题。最早的CGI程序很简单，将通过脚本将原来单机版的程序包装在一个进程里，来一个用户就启动一个进程。但明显这样承载不了多少用户，并且如果进程间需要共享资源还得通过进程间的通信机制，线程的出现缓解了这个问题。

线程的使用比较简单，如果你觉得这块代码需要并发，就把它放在单独的线程里执行，由系统负责调度，具体什么时候使用线程，要用多少个线程，由调用方决定，但定义方并不清楚调用方会如何使用自己的代码，很多并发问题都是因为误用导致的，比如Go中的map以及Java的HashMap都不是并发安全的，误用在多线程环境就会导致问题。另外也带来复杂度：

竞态条件（race conditions） 如果每个任务都是独立的，不需要共享任何资源，那线程也就非常简单。但世界往往是复杂的，总有一些资源需要共享，比如前面的例子，开发人员和市场人员同时需要和CEO商量一个方案，这时候CEO就成了竞态条件。
依赖关系以及执行顺序 如果线程之间的任务有依赖关系，需要等待以及通知机制来进行协调。比如前面的例子，如果产品和CEO讨论的方案依赖于市场和CEO讨论的方案，这时候就需要协调机制保证顺序。
为了解决上述问题，我们引入了许多复杂机制来保证：

Mutex(Lock) （Go里的sync包, Java的concurrent包）通过互斥量来保护数据，但有了锁，明显就降低了并发度。
semaphore 通过信号量来控制并发度或者作为线程间信号（signal）通知。
volatile Java专门引入了volatile关键词来，来降低只读情况下的锁的使用。
compare-and-swap 通过硬件提供的CAS机制保证原子性（atomic），也是降低锁的成本的机制。
如果说上面两个问题只是增加了复杂度，我们通过深入学习，严谨的CodeReview，全面的并发测试（比如Go语言中单元测试的时候加上-race参数），一定程度上能解决（当然这个也是有争议的，有论文认为当前的大多数并发程序没出问题只是并发度不够，如果CPU核数继续增加，程序运行的时间更长，很难保证不出问题）。但最让人头痛的还是下面这个问题：

系统里到底需要多少线程？

这个问题我们先从硬件资源入手，考虑下线程的成本：

内存（线程的栈空间）
每个线程都需要一个栈（Stack）空间来保存挂起（suspending）时的状态。Java的栈空间（64位VM）默认是1024k，不算别的内存，只是栈空间，启动1024个线程就要1G内存。虽然可以用-Xss参数控制，但由于线程是本质上也是进程，系统假定是要长期运行的，栈空间太小会导致稍复杂的递归调用（比如复杂点的正则表达式匹配）导致栈溢出。所以调整参数治标不治本。

调度成本（context-switch）
我在个人电脑上做的一个非严格测试，模拟两个线程互相唤醒轮流挂起，线程切换成本大约6000纳秒/次。这个还没考虑栈空间大小的影响。国外一篇论文专门分析线程切换的成本，基本上得出的结论是切换成本和栈空间使用大小直接相关。

CPU使用率
我们搞并发最主要的一个目标就是我们有了多核，想提高CPU利用率，最大限度的压榨硬件资源，从这个角度考虑，我们应该用多少线程呢？



这个我们可以通过一个公式计算出来，100/(15+5)*4=20，用20个线程最合适。但一方面网络的时间不是固定的，另外一方面，如果考虑到其他瓶颈资源呢？比如锁，比如数据库连接池，就会更复杂。

作为一个1岁多孩子的父亲，认为这个问题的难度好比你要写个给孩子喂饭的程序，需要考虑『给孩子喂多少饭合适？』，这个问题有以下回答以及策略：

孩子不吃了就好了（但孩子贪玩，不吃了可能是想去玩了）
孩子吃饱了就好了（废话，你怎么知道孩子吃饱了？孩子又不会说话）
逐渐增量，长期观察，然后计算一个平均值（这可能是我们调整线程常用的策略，但增量增加到多少合适呢？）
孩子吃吐了就别喂了（如果用逐渐增量的模式，通过外部观察，可能会到达这个边界条件。系统性能如果因为线程的增加倒退了，就别增加线程了）
没控制好边界，把孩子给给撑坏了 （这熊爸爸也太恐怖了。但调整线程的时候往往不小心可能就把系统搞挂了）
通过这个例子我们可以看出，从外部系统来观察，或者以经验的方式进行计算，都是非常困难的。于是结论是：

让孩子会说话，吃饱了自己说，自己学会吃饭，自管理是最佳方案。

然并卵，计算机不会自己说话，如何自管理？

但我们从以上的讨论可以得出一个结论：

线程的成本较高（内存，调度）不可能大规模创建
应该由语言或者框架动态解决这个问题
kernel 是如何调度线程的

在Linux中，线程是由进程来实现，线程就是轻量级进程（ lightweight process ），因此在Linux中，线程的调度是按照进程的调度方式来进行调度的，也就是说线程是调度单元。Linux这样实现的线程的好处的之一是：线程调度直接使用进程调度就可以了，没必要再搞一个进程内的线程调度器。

在Linux中，调度器是基于线程的调度策略（scheduling policy）和静态调度优先级（static scheduling priority）来决定那个线程来运行。

对于下面三种调度策略SCHED_OTHER, SCHED_IDLE, SCHED_BATCH，其调度优先级sched_priority是不起作用的，即可以看成其调度优先级为0；调度策略SCHED_FIFO和SCHED_RR是实时策略，他们的调度值范围是1到99，数值越大优先级越高，另外实时调度策略的线程总是比前面三种通常的调度策略优先级更高。

通常，调度器会为每个可能的调度优先级（sched_priority value）维护一个可运行的线程列表，并且是以最高静态优先级列表头部的线程作为下次调度的线程。所有的调度都是抢占式的：如果一个具有更高静态优先级的线程转换为可以运行了，那么当前运行的线程会被强制进入其等待的队列中。下面介绍几种常见的调度策略：

SCHED_OTHER：该策略是是默认的Linux分时调度（time-sharing scheduling）策略，它是Linux线程默认的调度策略。SCHED_OTHER策略的静态优先级总是为0，对于该策略列表上的线程，调度器是基于动态优先级（dynamic priority）来调度的，动态优先级是跟nice中相关(nice值可以由接口nice, setpriority,sched_setattr来设置)，该值会随着线程的运行时间而动态改变，以确保所有具有SCHED_OTHER策略的线程公平运行。在Linux上，nice值的范围是-20到+19，默认值为0；nice值越大则优先级越低，相比高nice值（低优先级）的进程，低nice值（高优先级）的进程可以获得更多的处理器时间。使用命令ps -el查看系统的进程列表，其中NI列就是进程对应的nice值；使用top命令，看到的NI列也是nice值。运行命令的时候可用nice –n xx cmd来调整cmd任务的nice值，xx的范围是-20~19之间。

SCHED_FIFO：先入先出调度策略（First in-first out scheduling）。该策略简单的说就是一旦线程占用cpu则一直运行，一直运行直到有更高优先级任务到达或自己放弃。

SCHED_RR：时间片轮转调度(Round-robin scheduling)。该策略是SCHED_FIFO基础上改进来的，他给每个线程增加了一个时间片限制，当时间片用完后，系统将把该线程置于队列末尾。放在队列尾保证了所有具有相同优先级的RR任务的调度公平。使用top命令，如果PR列的值为RT，则说明该进程采用的是实时策略，即调度策略是SCHED_FIFO或者为SCHED_RR，而对于非实时调度策略（比如SCHED_OTHER）的进程，该列的值是NI+20，以供Linux内核使用。

Goroutine 介绍

使用过 go 语言的同学都知道在 go 中实现一个 goroutine 是非常简单的，只需要使用关键字 go 就能运行一个 goroutine，那到底 goroutine 是什么？又是如何是实现的呢？这篇文章先试图讲清楚这两个问题，至于之后的具体实现和源码分析，我们随后写 blog 来阐述。

goroutine 翻译为 协程 字面意思是协同的程序？确实如此，就是协同的工作的程序。

咱们先看看协同的是啥，就是说有多个 goroutine 时，可以大家一起协同工作，那程序指啥呢？指的就是协同工作的内容了，咱们现在程序是运行在 cpu 上，所以就是一段 cpu 指令，对应就是咱们程序中的代码，因为咱们程序的代码分为 code data，就是 code 也就是咱们具体写的各个函数，因为咱们的 function 进过编译器编译后生成的咱可执行文件的 text segment，即 cpu 可执行的执行。

为什么需要协程

coroutine本质上是一种轻量级的thread，它的开销会比使用thread少很多。多个coroutine可以按照次序在一个thread里面执行，一个coroutine如果处于block状态，可以交出执行权，让其他的coroutine继续执行。

非阻塞I/O模型协程(Coroutines)使得开发者可以采用阻塞式的开发风格,却能够实现非阻塞I/O的效果隐式事件调度,

简单来说：协程十分轻量，可以在一个进程中执行有数以十万计的协程，依旧保持高性能。

goroutine 的一个主要特性就是它们的消耗；创建它们的初始内存成本很低廉（与需要 1 至 8MB 内存的传统 POSIX 线程形成鲜明对比）以及根据需要动态增长和缩减占用的资源。这使得 goroutine 会从 4096 字节的初始栈内存占用开始按需增长或缩减内存占用，而无需担心资源的耗尽。

实现 Goroutine 需要解决的问题

在上文中我讲了程序是啥，那么咱们这节就来看看要让 goroutine run 起来需要解决的问题有哪些？

code 运行起来后在电脑中最关键的数据有什么
咱们的 goroutine 运行在操作系统上面临的问题有哪些
咱们自身解决了上面的问题后，是不是引入新的问题
第一问题就得我们了解电脑的结构和运行是的原理，现代电脑都是 冯诺曼 体系的，而今天要回答这个问题，我们先得了解两个重要的组件，cpu 和 内存。有这些基础的同学都知道，cpu 和内存有几个重要的概念，寄存器 和 stack。 寄存器是 cpu 运行的重要组件可以和 cpu 来交换数据，而寄存是有限的，但是内存就要大的多，所以又变化而来了 stack 来和 cpu 交换数据。

当单个 goroutine 结束后，调度器如何调度下个 goroutine
当 goroutine 中存在系统调用并且系统调用阻塞了后，将会被 kernel 将这个线程挂起来，这样调度器就失去了调度当机会这样当情况怎么处理
若是采用新启动一个线程来调度，大规模当网络程序如何处理
当两个 goroutine 有交换数据当需求时，如何实现生产者和消费者当问题。
第二个问题:

我们运行在用户态，是没有中断或系统调用这样的机制来打断代码执行的，那么，一旦我们的 schedule()代码把控制权交给了任务的代码，我们下次的调度在什么时候发生？答案是，不会发生，只有靠任务主动调用 schedule()，我们才有机会进行调度，所以，这里的任务不能像线程一样依赖内核调度从而毫无顾忌的执行，我们的任务里一定要显式的调用 schedule()，这就是所谓的协作式(cooperative)调度。(虽然我们可以通过注册信号处理函数来模拟内核里的时钟中断并取得控制权，可问题在于，信号处理函数是由内核调用的，在其结束的时候，内核重新获得控制权，随后返回用户态并继续沿着信号发生时被中断的代码路径执行，从而我们无法在信号处理函数内进行任务切换)

堆栈。和内核调度线程的原理一样，我们也需要为每个任务单独分配堆栈，并且把其堆栈信息保存在任务属性里，在任务切换时也保存或恢复当前的SS:ESP。任务堆栈的空间可以是在当前线程的堆栈上分配，也可以是在堆上分配，但通常是在堆上分配比较好：几乎没有大小或任务总数的限制、堆栈大小可以动态扩展(gcc有split stack，但太复杂了)、便于把任务切换到其他线程。

Metadata 组织

既然是协作式的，那我们就得知道怎么样来协作，协作的隐含的一个意思就是可调度，既然要可调度，就得又调度的依据即数据，应为没有数据就没有调度的依据，而一般调度数据是通过埋点收集起来，goroutine 也不例外，通过自身 runtime 的数据来组织这些需要的数据。

通过上一节的说明我们大概知道了一个程序要运行起来几个重要的状态信息

寄存器的相关状态，如 PC,SP,Flag 等
程序运行起来后的 stack 状态
这两个数据是 goroutine 能调度运行的关键

syscall 和 network 的问题

goroutine 程序也是运行在操作系统系统之上，那么操作系统上的进程或者线程都是受操作系统管控的，我们知道和操作系统通讯只有两个方式一个中断，如 io，设备的中断，一个系统调用，其实这也是利用的中断。当操作系统陷入中断时就陷入内核这时，不是在用户态了，也就不受用户的管控，如果这是因为一个长时间的 io，操作系统会将这个线程或者进程调度让出，这是 golang 用户台的调度也就没有机会运行了。对于 network stack 上问题就更加突出，应为使用 golang 大都是网络程序，有着成千上万的网络链接。解决上面的两个 golang 主要使用了两个方式

监控 syscall，若是耗时的系统调用使用单独的线程服务
使用非阻塞的方式，在 network stack 使用的 epoll/kqueue 非阻塞网络技术
goroutine 之间的数据同步问题

引入 goroutine 时，当两个或者多个 goroutine 需要通讯时，如生产者和消费这样的场景是很常见，当消费者向生产者要数据时，生产者的数据还没有准备好，这是就应该让消费者挂起来，反正亦然。对于者问题，golang 使用 channel 来解决

CSP并发模型

CSP 描述这样一种并发模型：多个Process 使用一个 Channel 进行通信, 这个 Channel 连结的 Process 通常是匿名的，消息传递通常是同步的（有别于 Actor Model）。

CSP模型是上个世纪七十年代提出的，用于描述两个独立的并发实体通过共享的通讯 channel(管道)进行通信的并发模型。 CSP中channel是第一类对象，它不关注发送消息的实体，而关注与发送消息时使用的channel。

Golang 就是借用CSP模型的一些概念为之实现并发进行理论支持，其实从实际上出发，go语言并没有，完全实现了CSP模型的所有理论， 仅仅是借用了 process和channel这两个概念。process是在go语言上的表现就是 goroutine 是实际并发执行的实体，每个实体之间是通过channel通讯来实现数据共享。

Golang中使用 CSP中 channel 这个概念。channel 是被单独创建并且可以在进程之间传递，它的通信模式类似于 boss-worker 模式的，一个实体通过将消息发送到channel 中，然后又监听这个 channel 的实体处理，两个实体之间是匿名的，这个就实现实体中间的解耦，其中 channel 是同步的一个消息被发送到 channel 中，最终是一定要被另外的实体消费掉的，在实现原理上其实是一个阻塞的消息队列。

Goroutine 是实际并发执行的实体，它底层是使用协程(coroutine)实现并发，coroutine是一种运行在用户态的用户线程，类似于 greenthread，go底层选择使用coroutine的出发点是因为，它具有以下特点：

用户空间 避免了内核态和用户态的切换导致的成本
可以由语言和框架层进行调度
更小的栈空间允许创建大量的实例
参考

Golang 源码分析 - 调度器的实现分析
Goroutine（协程）为何能处理大并发？
浅析Linux线程调度
为什么 goroutine 的栈内存无穷大？
Coroutine模型 vs 非阻塞/异步IO(callback)
golang调度器学习
goroutine, channel 和 CSP
并发之痛 Thread，Goroutine，Actor
Golang 源码分析 - syscall
第 5 页（共 13 页）
本文是介绍操作系统存储管理的入门级文章,旨在介绍操作系统中存储管理的一般内容，本文主要围绕以下话题展开。

计算器系统中的存储结构

程序的链接和装入的概念

程序存储空间的分配

连续存储空间分配
离散存储空间分配(分页存储，分段存储，段页式存储)
虚拟存储器

请求分页存储
请求分段存储
置换算法
一丶计算机系统中的存储结构

计算机系统中的存储结构

上图中描述了计算机系统中的一般存储结构，从左往右存储资源的价格越来越便宜，但是存取的速度越来越贵。本文研究的存储管理指的主存管理以及少部分磁盘和主存之间的交互。

CPU寄存器，这是最昂贵的存储资源，里面一般缓存了些极其重要且频繁使用的数据。比如地址变换表的基地址等信息。
高速缓存，是为了提高CPU资源利用率而设计的存储结构，存放的时最近使用以及将来会使用的数据。越靠近CPU侧存取速度越快，存储价格越高。
主存，这是最主要的存储区域。运行中的程序(进程)都是被加载到主存中的。
磁盘，这是生活中最接触的存取区域，一般存放可执行文件，资源文件，配置文件等。IO操作就是指对磁盘进行的读写操作。很多场景下IO操作是系统性能的瓶颈
二丶程序的链接和装入

1、 装入

这是一个比较容易理解的概念，将位于硬盘上的代码加载至内存中的过程即为装入。在装入的过程中，存在一个转换的过程。该过程将程序代码中的逻辑地址转换物理内存中绝对地址。不同的地址转换方式对应三种不同装入方式

绝对装入
在程序代码编写的过程就确定了存储的物理地址。此时逻辑地址和物理地址保持一致。在现在操作系统中不会采用这种方式

可重定位装入
在程序加载到内存地址中是，其可以存储到内存的任意位置。物理地址 = 逻辑地址(相对地址) + 物理内存加载处的起始地址。 可重定位的装入方式比绝对装入灵活多了，但是其存储地址在刚载入内存后就固定了，后续不可以移动存储位置。在现在操作系统中也不使用这种方式

运行时装入
目前主流的装入方式，其在程序加载到内存时，不会将逻辑地址转换物理地址，仅仅在程序代码被执行时，才将逻辑地址转换为物理地址。 运行时装入，允许程序在在读内存后，依旧能够在存储空间中移动。能满足内存整理等场景的要求。

2、链接

链接也是一个比较易懂的概念，和装入的过程颇为相似。程序在经过编译之后，将形成多个目标模块，将这多个目标模块组合成一个整体的过程即为链接。根据这些目标模块组合的不同时机，链接分为以下三类

静态链接
在程序运行之间，就将像目标模块以及库函数合=链接成一个整体模块。

装入时链接
在装入目标模块的时候，一边装入一边链接

动态链接
在使用到相关程序逻辑的时候，开始链接。

三丶程序存储空间的分配

在程序执行完链接和装入过程后，位于硬盘上的代码就将载入内存中。此处必须要为程序分配其所需要的存储空间。依据分配存储空间是否连续这一特点，可将存储空间的分配分为连续分配以及离散分配

1、连续存储空间分配

单一连续存储分配

该种方法适用于单用户，单任务的操作系统。其将主内存分为系统内存和工作内存。系统内存负责载入操作系统等内容。工作内存仅载入需执行的任务，每个被加载的任务将独占内存。系统内存和工作内存之间相互独立。

固定存储分配

该方法适用于适用于多任务操作系统。其将主内存分为多个大小相等的子内存区域，当存在任务加载需求的时候，将任务加载去子内存区域。该方法采用的固定分区，灵活性不够。不能解决分区过大导致的内存碎片的问题，也不能解决分区过小导致无法载入大作业的问题。(也可以将内存固定划分为不等的子内存区域，又称为不等分区固定分配)

动态存储空间分配

在任务加载进内存时，依据任务所需内存大小实现按需分配。动态存储空间分配，看似解决了内存碎片问题，实际上并不是这样的。在动态存储空间分配时，多次内存分配操作，会产生一系列地址不联系，大小各异的内存空间。当这些内存空间被回收后，将退化成不等分区的固定存储分配。

可重定位的分区分配

该存储方式，在动态存储空间分配上添加了内存整理功能。若当前内存空间不能满足任务所需内存空间时，其会将已分配的内存空间全部移动，使未分配的内存空间形成一片连续的地址空间。该种方法则要求程序的装入方式是动态装入

上述介绍的四种存储空间分配方法被称为连续的分配是因为其不能分割作业存储。只能将作业存储在一块连续内存空间中，并不能将作为划分成更小的单位进行分块存储。

2、离散存储空间分配

离散存储空间分配是指，其能将任务分割成更小的存储单位。分割后的存储单位连续存储，而存储单位与存储单位之间并不要求连续。通过将任务拆分进行存储的方法，能极大的提高存储空间的利用率。

页式存储空间分配

这里将页定义为一个固定大小的存储单位。在将任务载入内存时，一个完整的任务可以被划分成多页。每页独立的存储到内存空间中，内存空间中存储位置可用物理页号描述。每页的存储是连续，页与页之间的存储并不是连续的，而是离散存储的。
为了建立任务的地址与物理空间地址之间的联系。在内存表中将建立页表，完成页号到物理号的映射

页式存储空间分配

段式存储空间分配

段式存储的方法和页式存储的方法手段都是一致。将任务以段为存储单位，将任务分成多段进而离散存储。在内存中同样维护了一张段表。段表和页表结构是一致的。

段式存储空间分配

那么页式存储和段式存储这两者的差别究竟何在呢？ 以下是页式存储和段式存储的差别

页是信息的物理单位，分页式为了减少内存碎片，提高内存利用率而提出的。段是信息的逻辑单位，它包含一组完成的逻辑意义，其不仅能提高内存利用率，而且在方便编程，信息共享，信息保护等方面均有好处。

页的大小是有操作系统固定设计的，在系统中页的大小是固定且唯一的。段长度并不是固定的，取决于用户所编写的程序，通常由编译程序在对源程序进行编译时，根据信息的性质决定。

段页式存储空间分配

该存储方式实际上是，分页存储和分段存储的组合。先将任务按照段进行划分，然后每段按照分页的方式进行存储，即为段页式存储。下文将比较分页存储，分段存储，以及段页式存储内存地址的变化

分页存储地址(页号:页内偏移地址)

分段存储地址(段号:段内偏移地址)

段页式存储(段号段内偏移页号:页内偏移地址)

四丶虚拟存储器

虚拟存储器是现在操作系统广泛使用的一种存储方式，虚拟存储能在不对物理内存扩容的基础上，保证能够运行更多更大的内存任务。虚拟存储器和常规存储器的不同之处在于，虚拟存储器不要求你任务一次性全部载入内存，而是按需载入内存。并且能在内存空间受限时，将闲置的内存作业调出内存，这种将内存作业调出内存的过程称为置换，完成置换过程的方式则称为置换算法。在上述过程中，不将作业一次性完全载入内存，显然是建立在分页存储或者分段存储的基础上，下文对这两种情况分别介绍

请求分页存储

请求分页存储具有两点内容需要理解:

分页加载，按需加载
请求分页存储将任务以页为单位进行划分，在载入内存时，并不将全部页面载入。而是将部分必须的页面载入内存，其他的页面在程序运行中，若使用则按需载入内存。

分页置换
在内存空间紧张时，会将程序中某些使用或者近期不在使用的页面，从内存置换到磁盘中去。

在请求分页存储中，内存中维护的页表不再是简单的页号到内存物理号之间的映射了。其页表结构一般如下:

请求分页存储

页号，这个字段代表分页顺序
物理块号，这个字段代表，该页在内存中的位置
状态位P，该状态位用来标识该页是否载入内存，true代表载入内存，false代表未载入内存
访问字段，该状态位是统计状态位，可以用来记录该页最近被访问的次数
修改位，该位用来标识，该页载入到内存后是否被修改过了。若内存中修改过后，其置换到外存时，需要回写回去。如果没有修改过，那么其置换到外存时，无须回写回去。
外存地址，该位存储该也在外存中的地址。一般来说，在载入内存后，外存上依旧会留有一一份拷贝信息。
请求分段存储

请求分段存储与请求分页存储及其相似。唯一的区别便是，载入和置换的单位从页转换到了段。

置换算法

置换算法，在虚拟存储器中是非常重要的内容。在虚拟存储器设计理念中，当内存资源紧张的时候，会依据置换算法将内存中的页面置换到外存中。此处介绍两种置换算法

LRU(Least Recently used,最近最久使用算法)

最近最久未使用算法，在页面项中添加了访问时间字段T，记录最近一次访问到目前过去的时间。在需要进行页面置换时候，将T最大的页面置换出去。

LFU(Least Frequently used，最少使用算法)

最少使用算法，在页面项中添加了访问频率字段F，计算最近一段时间内该页面被访问的频率。在需要进行页面置换时候，将F最小的页面置换出去

作者：涂印
链接：https://juejin.im/post/5bc5e39be51d450e597b9fdc
来源：掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

第 6 页（共 13 页）
我们首先来看看服务器编程的模型，客户端发来的请求服务端会产生一个进程来对其进行服务，每当来一个客户请求就产生一个进程来服务，然而进程不可能无限制的产生，因此为了解决大量客户端访问的问题，引入了IO复用技术。

即：一个进程可以同时对多个客户请求进行服务。

I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。

也就是说IO复用的“介质”是进程(准确的说复用的是select和poll，因为进程也是靠调用select和poll来实现的)，复用一个进程(select和poll)来对多个IO进行服务，虽然客户端发来的IO是并发的但是IO所需的读写数据多数情况下是没有准备好的，因此就可以利用一个函数(select和poll)来监听IO所需的这些数据的状态，一旦IO有数据可以进行读写了，进程就来对这样的IO进行服务。

IO多路复用指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。

IO多路复用适用如下场合：

当客户处理多个描述字时（一般是交互式输入和网络套接口），必须使用I/O复用。
当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。
如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。
如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。
如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。
一、基本概念

在进行解释之前，首先要说明几个概念：

用户空间和内核空间
进程切换
进程的阻塞
文件描述符
缓存 I/O
用户空间与内核空间

现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。

进程切换

为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。

从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化：

保存处理机上下文，包括程序计数器和其他寄存器。
更新PCB信息。
把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。
选择另一个进程执行，并更新其PCB。
更新内存管理的数据结构。
恢复处理机上下文。
注：总而言之就是很耗资源。

进程的阻塞

正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。

当进程进入阻塞状态，是不占用CPU资源的。

文件描述符

文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。

文件描述符在形式上是一个非负整数。 实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。

缓存 I/O

缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。

缓存 I/O 的缺点：

数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。

IO模式

刚才说了，对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：

等待数据准备 (Waiting for the data to be ready)

将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)

正式因为这两个阶段，linux系统产生了下面五种网络模式的方案。

阻塞 I/O（blocking IO）
非阻塞 I/O（nonblocking IO）
I/O 多路复用（ IO multiplexing）
信号驱动 I/O（ signal driven IO）
异步 I/O（asynchronous IO）
注：由于signal driven IO在实际中并不常用，所以我这只提及剩下的四种IO Model。

阻塞 I/O（blocking IO）

在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：

阻塞 I/O（blocking IO）

当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。

所以，blocking IO的特点就是在IO执行的两个阶段都被block了。

非阻塞 I/O（nonblocking IO）

linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：

非阻塞 I/O（nonblocking IO）

当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。

所以，nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有。

I/O 多路复用（ IO multiplexing）

IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。

I/O 多路复用（ IO multiplexing）

当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。

所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。

这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。

所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。）

在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。

异步 I/O（asynchronous IO）

inux下的asynchronous IO其实用得很少。先看一下它的流程：

异步 I/O（asynchronous IO）

用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。

Linux的socket 事件wakeup callback机制

在介绍select、poll、epoll前，有必要说说linux(2.6+)内核的事件wakeup callback机制，这是IO多路复用机制存在的本质。Linux通过socket睡眠队列来管理所有等待socket的某个事件的process，同时通过wakeup机制来异步唤醒整个睡眠队列上等待事件的process，通知process相关事件发生。通常情况，socket的事件发生的时候，其会顺序遍历socket睡眠队列上的每个process节点，调用每个process节点挂载的callback函数。在遍历的过程中，如果遇到某个节点是排他的，那么就终止遍历，总体上会涉及两大逻辑：（1）睡眠等待逻辑；（2）唤醒逻辑。

睡眠等待逻辑：涉及select、poll、epoll_wait的阻塞等待逻辑

select、poll、epoll_wait陷入内核，判断监控的socket是否有关心的事件发生了，如果没，则为当前process构建一个wait_entry节点，然后插入到监控socket的sleep_list
进入循环的schedule直到关心的事件发生了
关心的事件发生后，将当前process的wait_entry节点从socket的sleep_list中删除。
唤醒逻辑

socket的事件发生了，然后socket顺序遍历其睡眠队列，依次调用每个wait_entry节点的callback函数
直到完成队列的遍历或遇到某个wait_entry节点是排他的才停止。
一般情况下callback包含两个逻辑：
wait_entry自定义的私有逻辑；
唤醒的公共逻辑，主要用于将该wait_entry的process放入CPU的就绪队列，让CPU随后可以调度其执行。
二、select

基本原理

在一个高性能的网络服务上，大多情况下一个服务进程(线程)process需要同时处理多个socket，我们需要公平对待所有socket，对于read而言，那个socket有数据可读，process就去读取该socket的数据来处理。于是对于read，一个朴素的需求就是关心的N个socket是否有数据”可读”，也就是我们期待”可读”事件的通知，而不是盲目地对每个socket调用recv/recvfrom来尝试接收数据。我们应该block在等待事件的发生上，这个事件简单点就是”关心的N个socket中一个或多个socket有数据可读了”，当block解除的时候，就意味着，我们一定可以找到一个或多个socket上有可读的数据。另一方面，根据上面的socket wakeup callback机制，我们不知道什么时候，哪个socket会有读事件发生，于是，process需要同时插入到这N个socket的sleep_list上等待任意一个socket可读事件发生而被唤醒，当时process被唤醒的时候，其callback里面应该有个逻辑去检查具体那些socket可读了。

于是，select的多路复用逻辑就清晰了，select为每个socket引入一个poll逻辑，该poll逻辑用于收集socket发生的事件，对于可读事件来说，简单伪码如下：

poll()
{
    //其他逻辑
    if (recieve queque is not empty)
    {
        sk_event |= POLL_IN；
    }
   //其他逻辑
}
select 函数

接下来就到select的逻辑了，下面是select的函数原型：5个参数，后面4个参数都是in/out类型(值可能会被修改返回)

#include <sys/select.h>
#include >sys/time.h>

int select(int maxfdp1, fd_set *readset, fd_set *writeset, fd_set *exceptset, const struct timeval *timeout);
返回值：

若有就绪描述符返回其数目，若超时则为0，若出错则为-1

参数

maxfdp1 指定待测试的描述字个数。
fd_set 则是配合select模型的重点数据结构，用来存放描述符的集合。
timeout 表示告知内核等待所指定描述字中的任何一个就绪可花多少时间。其timeval结构用于指定这段时间的秒数和微秒数。

struct timeval{
      long tv_sec;   //seconds
     long tv_usec;  //microseconds
};
这个参数有三种可能：

永远等待下去：仅在有一个描述字准备好I/O时才返回。为此，把该参数设置为空指针NULL。
等待一段固定时间：在有一个描述字准备好I/O时返回，但是不超过由该参数所指向的timeval结构中指定的秒数和微秒数。
根本不等待：检查描述字后立即返回，这称为轮询。为此，该参数必须指向一个timeval结构，而且其中的定时器值必须为0。
当用户process调用select的时候，select会将需要监控的readfds集合拷贝到内核空间（假设监控的仅仅是socket可读），然后遍历自己监控的socket sk，挨个调用sk的poll逻辑以便检查该sk是否有可读事件，遍历完所有的sk后，如果没有任何一个sk可读，那么select会调用schedule_timeout进入schedule循环，使得process进入睡眠。如果在timeout时间内某个sk上有数据可读了，或者等待timeout了，则调用select的process会被唤醒，接下来select就是遍历监控的sk集合，挨个收集可读事件并返回给用户了，相应的伪码如下：

for (sk in readfds)
{
    sk_event.evt = sk.poll();
    sk_event.sk = sk;
    ret_event_for_process;
}
select 函数调用过程

select调度过程

多客户端请求服务端，服务端与各客户端保持长连接并且能接收到各客户端数据大体思路如下：

使用copy_from_user从用户空间拷贝fd_set到内核空间

注册回调函数__pollwait

遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll,udp_poll或者datagram_poll）

以tcp_poll为例，其核心实现就是__pollwait，也就是上面注册的回调函数。

__pollwait的主要工作就是把current（当前进程）挂到设备的等待队列中，不同的设备有不同的等待队列，对于tcp_poll来说，其等待队列是sk->sk_sleep（注意把进程挂到等待队列中并不代表进程已经睡眠了）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒了。

poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值。

如果遍历完所有的fd，还没有返回一个可读写的mask掩码，则会调用schedule_timeout是调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间（schedule_timeout指定），还是没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有没有就绪的fd。

把fd_set从内核空间拷贝到用户空间。

通过上面的select逻辑过程分析，相信大家都意识到，select存在两个问题：

被监控的fds需要从用户空间拷贝到内核空间
为了减少数据拷贝带来的性能损坏，内核对被监控的fds集合大小做了限制，并且这个是通过宏控制的，大小不可改变(限制为1024)。

被监控的fds集合中，只要有一个有数据可读，整个socket集合就会被遍历一次调用sk的poll函数收集可读事件
由于当初的需求是朴素，仅仅关心是否有数据可读这样一个事件，当事件通知来的时候，由于数据的到来是异步的，我们不知道事件来的时候，有多少个被监控的socket有数据可读了，于是，只能挨个遍历每个socket来收集可读事件。

select 缺点

到这里，我们有三个问题需要解决：

被监控的fds集合限制为1024，1024太小了，我们希望能够有个比较大的可监控fds集合

fds集合需要从用户空间拷贝到内核空间的问题，我们希望不需要拷贝

当被监控的fds中某些有数据可读的时候，我们希望通知更加精细一点，就是我们希望能够从通知中得到有可读事件的fds列表，而不是需要遍历整个fds来收集。

三、Poll

select遗留的三个问题中，问题(1)是用法限制问题，问题(2)和(3)则是性能问题。poll和select非常相似，poll并没着手解决性能问题，poll只是解决了select的问题(1)fds集合大小1024限制问题。

下面是poll的函数原型，poll改变了fds集合的描述方式，使用了pollfd结构而不是select的fd_set结构，使得poll支持的fds集合限制远大于select的1024。poll虽然解决了fds集合大小1024的限制问题，但是，它并没改变大量描述符数组被整体复制于用户态和内核态的地址空间之间，以及个别描述符就绪触发整体描述符集合的遍历的低效问题。poll随着监控的socket集合的增加性能线性下降，poll不适合用于大并发场景。

int poll(struct pollfd *fds, nfds_t nfds, int timeout);
四、epoll

select遗留的三个问题，问题(1)是比较好解决，poll简单两三下就解决掉了，但是poll的解决有点鸡肋。要解决问题(2)和(3)似乎比较棘手，要怎么解决呢？我们知道，在计算机行业中，有两种解决问题的思想：

计算机科学领域的任何问题, 都可以通过添加一个中间层来解决
变集中(中央)处理为分散(分布式)处理
假设现实中，有1百万个客户端同时与一个服务器保持着tcp连接，而每一个时刻，通常只有几百上千个tcp连接是活跃的，这时候我们仍然使用select/poll机制，kernel必须在搜寻完100万个fd之后，才能找到其中状态是active的，这样资源消耗大而且效率低下。

fds集合拷贝问题的解决

对于IO多路复用，有两件事是必须要做的(对于监控可读事件而言)：

准备好需要监控的fds集合；

探测并返回fds集合中哪些fd可读了。细看select或poll的函数原型，我们会发现，每次调用select或poll都在重复地准备(集中处理)整个需要监控的fds集合。然而对于频繁调用的select或poll而言，fds集合的变化频率要低得多，我们没必要每次都重新准备(集中处理)整个fds集合。

于是，epoll引入了epoll_ctl系统调用，将高频调用的epoll_wait和低频的epoll_ctl隔离开。同时，epoll_ctl通过(EPOLL_CTL_ADD、EPOLL_CTL_MOD、EPOLL_CTL_DEL)三个操作来分散对需要监控的fds集合的修改，做到了有变化才变更，将select/poll高频、大块内存拷贝(集中处理)变成epoll_ctl的低频、小块内存的拷贝(分散处理)，避免了大量的内存拷贝。

按需遍历就绪的fds集合

为了做到只遍历就绪的fd，我们需要有个地方来组织那些已经就绪的fd。为此，epoll引入了一个中间层，一个双向链表(ready_list)，一个单独的睡眠队列(single_epoll_wait_list)，并且，与select或poll不同的是，epoll的process不需要同时插入到多路复用的socket集合的所有睡眠队列中，相反process只是插入到中间层的epoll的单独睡眠队列中，process睡眠在epoll的单独队列上，等待事件的发生。

于是，整个过来可以分为以下几个逻辑：

epoll_ctl EPOLL_CTL_ADD逻辑

构建睡眠实体wait_entry_sk，将当前socket sk关联给wait_entry_sk，并设置wait_entry_sk的回调函数为epoll_callback_sk
将wait_entry_sk排入当前socket sk的睡眠队列上
回调函数epoll_callback_sk的逻辑如下：

将之前关联的sk排入epoll的ready_list
然后唤醒epoll的单独睡眠队列single_epoll_wait_list
epoll_wait逻辑

构建睡眠实体wait_entry_proc，将当前process关联给wait_entry_proc，并设置回调函数为epoll_callback_proc
判断epoll的ready_list是否为空，如果为空，则将wait_entry_proc排入epoll的single_epoll_wait_list中，随后进入schedule循环，这会导致调用epoll_wait的process睡眠。
wait_entry_proc被事件唤醒或超时醒来，wait_entry_proc将被从single_epoll_wait_list移除掉，然后wait_entry_proc执行回调函数epoll_callback_proc
回调函数epoll_callback_proc的逻辑如下：

遍历epoll的ready_list，挨个调用每个sk的poll逻辑收集发生的事件，对于监控可读事件而已，ready_list上的每个sk都是有数据可读的，这里的遍历必要的(不同于select/poll的遍历，它不管有没数据可读都需要遍历一些来判断，这样就做了很多无用功。)
将每个sk收集到的事件，通过epoll_wait传入的events数组回传并唤醒相应的process。
epoll唤醒逻辑
整个epoll的协议栈唤醒逻辑如下(对于可读事件而言)：

协议数据包到达网卡并被排入socket sk的接收队列
睡眠在sk的睡眠队列wait_entry被唤醒，wait_entry_sk的回调函数epoll_callback_sk被执行
epoll_callback_sk将当前sk插入epoll的ready_list中
唤醒睡眠在epoll的单独睡眠队列single_epoll_wait_list的wait_entry，wait_entry_proc被唤醒执行回调函数epoll_callback_proc
遍历epoll的ready_list，挨个调用每个sk的poll逻辑收集发生的事件
将每个sk收集到的事件，通过epoll_wait传入的events数组回传并唤醒相应的process。
epoll巧妙的引入一个中间层解决了大量监控socket的无效遍历问题。细心的同学会发现，epoll在中间层上为每个监控的socket准备了一个单独的回调函数epoll_callback_sk，而对于select/poll，所有的socket都公用一个相同的回调函数。正是这个单独的回调epoll_callback_sk使得每个socket都能单独处理自身，当自己就绪的时候将自身socket挂入epoll的ready_list。

同时，epoll引入了一个睡眠队列single_epoll_wait_list，分割了两类睡眠等待。process不再睡眠在所有的socket的睡眠队列上，而是睡眠在epoll的睡眠队列上，在等待”任意一个socket可读就绪”事件。而中间wait_entry_sk则代替process睡眠在具体的socket上，当socket就绪的时候，它就可以处理自身了。

ET(Edge Triggered 边沿触发) vs LT(Level Triggered 水平触发)

ET vs LT - 概念

说到Epoll就不能不说说Epoll事件的两种模式了，下面是两个模式的基本概念

Edge Triggered (ET) 边沿触发

socket的接收缓冲区状态变化时触发读事件，即空的接收缓冲区刚接收到数据时触发读事件

socket的发送缓冲区状态变化时触发写事件，即满的缓冲区刚空出空间时触发读事件

仅在缓冲区状态变化时触发事件，比如数据缓冲去从无到有的时候(不可读-可读)

Level Triggered (LT) 水平触发

socket接收缓冲区不为空，有数据可读，则读事件一直触发

socket发送缓冲区不满可以继续写入数据，则写事件一直触发

符合思维习惯，epoll_wait返回的事件就是socket的状态

通常情况下，大家都认为ET模式更为高效，实际上是不是呢？下面我们来说说两种模式的本质：

上文所述 epoll唤醒逻辑 的第五个步骤

遍历epoll的ready_list，挨个调用每个sk的poll逻辑收集发生的事件

大家是不是有个疑问呢：挂在ready_list上的sk什么时候会被移除掉呢？其实，sk从ready_list移除的时机正是区分两种事件模式的本质。因为，通过上面的介绍，我们知道ready_list是否为空是epoll_wait是否返回的条件。于是，在两种事件模式下，步骤5如下：

对于Edge Triggered (ET) 边沿触发：

遍历epoll的ready_list，将sk从ready_list中移除，然后调用该sk的poll逻辑收集发生的事件

对于Level Triggered (LT) 水平触发：

遍历epoll的ready_list，将sk从ready_list中移除，然后调用该sk的poll逻辑收集发生的事件
如果该sk的poll函数返回了关心的事件(对于可读事件来说，就是POLL_IN事件)，那么该sk被重新加入到epoll的ready_list中。
对于可读事件而言，在ET模式下，如果某个socket有新的数据到达，那么该sk就会被排入epoll的ready_list，从而epoll_wait就一定能收到可读事件的通知(调用sk的poll逻辑一定能收集到可读事件)。于是，我们通常理解的缓冲区状态变化(从无到有)的理解是不准确的，准确的理解应该是是否有新的数据达到缓冲区。
而在LT模式下，某个sk被探测到有数据可读，那么该sk会被重新加入到read_list，那么在该sk的数据被全部取走前，下次调用epoll_wait就一定能够收到该sk的可读事件(调用sk的poll逻辑一定能收集到可读事件)，从而epoll_wait就能返回。

ET vs LT - 性能

通过上面的概念介绍，我们知道对于可读事件而言，LT比ET多了两个操作：(1)对ready_list的遍历的时候，对于收集到可读事件的sk会重新放入ready_list；(2)下次epoll_wait的时候会再次遍历上次重新放入的sk，如果sk本身没有数据可读了，那么这次遍历就变得多余了。

在服务端有海量活跃socket的时候，LT模式下，epoll_wait返回的时候，会有海量的socket sk重新放入ready_list。如果，用户在第一次epoll_wait返回的时候，将有数据的socket都处理掉了，那么下次epoll_wait的时候，上次epoll_wait重新入ready_list的sk被再次遍历就有点多余，这个时候LT确实会带来一些性能损失。然而，实际上会存在很多多余的遍历么？

先不说第一次epoll_wait返回的时候，用户进程能否都将有数据返回的socket处理掉。在用户处理的过程中，如果该socket有新的数据上来，那么协议栈发现sk已经在ready_list中了，那么就不需要再次放入ready_list，也就是在LT模式下，对该sk的再次遍历不是多余的，是有效的。同时，我们回归epoll高效的场景在于，服务器有海量socket，但是活跃socket较少的情况下才会体现出epoll的高效、高性能。因此，在实际的应用场合，绝大多数情况下，ET模式在性能上并不会比LT模式具有压倒性的优势，至少，目前还没有实际应用场合的测试表面ET比LT性能更好。

ET vs LT - 复杂度

我们知道，对于可读事件而言，在阻塞模式下，是无法识别队列空的事件的，并且，事件通知机制，仅仅是通知有数据，并不会通知有多少数据。于是，在阻塞模式下，在epoll_wait返回的时候，我们对某个socket_fd调用recv或read读取并返回了一些数据的时候，我们不能再次直接调用recv或read，因为，如果socket_fd已经无数据可读的时候，进程就会阻塞在该socket_fd的recv或read调用上，这样就影响了IO多路复用的逻辑(我们希望是阻塞在所有被监控socket的epoll_wait调用上，而不是单独某个socket_fd上)，造成其他socket饿死，即使有数据来了，也无法处理。

接下来，我们只能再次调用epoll_wait来探测一些socket_fd，看是否还有数据可读。在LT模式下，如果socket_fd还有数据可读，那么epoll_wait就一定能够返回，接着，我们就可以对该socket_fd调用recv或read读取数据。然而，在ET模式下，尽管socket_fd还是数据可读，但是如果没有新的数据上来，那么epoll_wait是不会通知可读事件的。这个时候，epoll_wait阻塞住了，这下子坑爹了，明明有数据你不处理，非要等新的数据来了在处理，那么我们就死扛咯，看谁先忍不住。

等等，在阻塞模式下，不是不能用ET的么？是的，正是因为有这样的缺点，ET强制需要在非阻塞模式下使用。在ET模式下，epoll_wait返回socket_fd有数据可读，我们必须要读完所有数据才能离开。因为，如果不读完，epoll不会在通知你了，虽然有新的数据到来的时候，会再次通知，但是我们并不知道新数据会不会来，以及什么时候会来。由于在阻塞模式下，我们是无法通过recv/read来探测空数据事件，于是，我们必须采用非阻塞模式，一直read直到EAGAIN。因此，ET要求socket_fd非阻塞也就不难理解了。

另外，epoll_wait原本的语意是：监控并探测socket是否有数据可读(对于读事件而言)。LT模式保留了其原本的语意，只要socket还有数据可读，它就能不断反馈，于是，我们想什么时候读取处理都可以，我们永远有再次poll的机会去探测是否有数据可以处理，这样带来了编程上的很大方便，不容易死锁造成某些socket饿死。相反，ET模式修改了epoll_wait原本的语意，变成了：监控并探测socket是否有新的数据可读。

于是，在epoll_wait返回socket_fd可读的时候，我们需要小心处理，要不然会造成死锁和socket饿死现象。典型如listen_fd返回可读的时候，我们需要不断的accept直到EAGAIN。假设同时有三个请求到达，epoll_wait返回listen_fd可读，这个时候，如果仅仅accept一次拿走一个请求去处理，那么就会留下两个请求，如果这个时候一直没有新的请求到达，那么再次调用epoll_wait是不会通知listen_fd可读的，于是epoll_wait只能睡眠到超时才返回，遗留下来的两个请求一直得不到处理，处于饿死状态。

ET vs LT - 总结

最后总结一下，ET和LT模式下epoll_wait返回的条件

ET - 对于读操作

当接收缓冲buffer内待读数据增加的时候时候(由空变为不空的时候、或者有新的数据进入缓冲buffer)

调用epoll_ctl(EPOLL_CTL_MOD)来改变socket_fd的监控事件，也就是重新mod socket_fd的EPOLLIN事件，并且接收缓冲buffer内还有数据没读取。(这里不能是EPOLL_CTL_ADD的原因是，epoll不允许重复ADD的，除非先DEL了，再ADD)，因为epoll_ctl(ADD或MOD)会调用sk的poll逻辑来检查是否有关心的事件，如果有，就会将该sk加入到epoll的ready_list中，下次调用epoll_wait的时候，就会遍历到该sk，然后会重新收集到关心的事件返回。

ET - 对于写操作

发送缓冲buffer内待发送的数据减少的时候(由满状态变为不满状态的时候、或者有部分数据被发出去的时候)
调用epoll_ctl(EPOLL_CTL_MOD)来改变socket_fd的监控事件，也就是重新mod socket_fd的EPOLLOUT事件，并且发送缓冲buffer还没满的时候。
LT - 对于读操作

LT就简单多了，唯一的条件就是，接收缓冲buffer内有可读数据的时候

LT - 对于写操作

LT就简单多了，唯一的条件就是，发送缓冲buffer还没满的时候在绝大多少情况下，ET模式并不会比LT模式更为高效，同时，ET模式带来了不好理解的语意，这样容易造成编程上面的复杂逻辑和坑点。因此，建议还是采用LT模式来编程更为舒爽。

参考

IO多路复用之select函数详解：https://blog.csdn.net/lixungogogo/article/details/52219951
select、poll、epoll之间的区别总结:http://www.cnblogs.com/Anker/p/3265058.html
从BIO、NIO到Linux下的IO多路复用:https://github.com/justtreee/blog/issues/17
Linux IO模式及 select、poll、epoll详解:https://segmentfault.com/a/1190000003063859
大话 Select、Poll、Epoll:https://cloud.tencent.com/developer/article/1005481

第 7 页（共 13 页）
进程间通信（IPC）的一般目的，大概有数据传输、共享数据、通知事件、资源共享和进程控制等。但是我们知道，对于每一个进程来说这个进程看到属于它的一块内存资源，这块资源是它所独占的，所以进程之间的通信就会比较麻烦，原理就是需要让不同的进程间能够看到一份公共的资源。所以交换数据必须通过内核,在内核中开辟一块缓冲区,进程1把数据从用户空间 拷到内核缓冲区,进程2再从内核缓冲区把数据读走,内核提供的这种机制称为进程间通信。一般我们采用的进程间通信方式有

管道（pipe）和有名管道（FIFO）
信号（signal）
消息队列
共享内存
信号量
套接字（socket)
匿名管道(pipe)

管道可用于具有亲缘关系进程间的通信，有名管道克服了管道没有名字的限制，因此，除具有管道所具有的功能外，它还允许无亲缘关系进程间的通信；

实现机制：

管道是由内核管理的一个缓冲区，相当于我们放入内存中的一个纸条。管道的一端连接一个进程的输出。这个进程会向管道中放入信息。管道的另一端连接一个进程的输入，这个进程取出被放入管道的信息。一个缓冲区不需要很大，它被设计成为环形的数据结构，以便管道可以被循环利用。当管道中没有信息的话，从管道中读取的进程会等待，直到另一端的进程放入信息。当管道被放满信息的时候，尝试放入信息的进程会等待，直到另一端的进程取出信息。当两个进程都终结的时候，管道也自动消失。

管道(pipe)

从原理上，管道利用fork机制建立，从而让两个进程可以连接到同一个PIPE上。最开始的时候，上面的两个箭头都连接在同一个进程Process 1上(连接在Process 1上的两个箭头)。当fork复制进程的时候，会将这两个连接也复制到新的进程(Process 2)。随后，每个进程关闭自己不需要的一个连接 (两个黑色的箭头被关闭; Process 1关闭从PIPE来的输入连接，Process 2关闭输出到PIPE的连接)，这样，剩下的红色连接就构成了如上图的PIPE。

管道(pipe)

实现细节：

在 Linux 中，管道的实现并没有使用专门的数据结构，而是借助了文件系统的file结构和VFS的索引节点inode。通过将两个 file 结构指向同一个临时的 VFS 索引节点，而这个 VFS 索引节点又指向一个物理页面而实现的。如下图

使用文件和iNode模拟管道

有两个 file 数据结构，但它们定义文件操作例程地址是不同的，其中一个是向管道中写入数据的例程地址，而另一个是从管道中读出数据的例程地址。这样，用户程序的系统调用仍然是通常的文件操作，而内核却利用这种抽象机制实现了管道这一特殊操作。

关于管道的读写

管道实现的源代码在fs/pipe.c中，在pipe.c中有很多函数，其中有两个函数比较重要，即管道读函数pipe_read()和管道写函数pipe_wrtie()。管道写函数通过将字节复制到 VFS 索引节点指向的物理内存而写入数据，而管道读函数则通过复制物理内存中的字节而读出数据。当然，内核必须利用一定的机制同步对管道的访问，为此，内核使用了锁、等待队列和信号。

当写进程向管道中写入时，它利用标准的库函数write()，系统根据库函数传递的文件描述符，可找到该文件的 file 结构。file 结构中指定了用来进行写操作的函数（即写入函数）地址，于是，内核调用该函数完成写操作。写入函数在向内存中写入数据之前，必须首先检查 VFS 索引节点中的信息，同时满足如下条件时，才能进行实际的内存复制工作：

内存中有足够的空间可容纳所有要写入的数据；

内存没有被读程序锁定。

如果同时满足上述条件，写入函数首先锁定内存，然后从写进程的地址空间中复制数据到内存。否则，写入进程就休眠在 VFS 索引节点的等待队列中，接下来，内核将调用调度程序，而调度程序会选择其他进程运行。写入进程实际处于可中断的等待状态，当内存中有足够的空间可以容纳写入数据，或内存被解锁时，读取进程会唤醒写入进程，这时，写入进程将接收到信号。当数据写入内存之后，内存被解锁，而所有休眠在索引节点的读取进程会被唤醒。

管道的读取过程和写入过程类似。但是，进程可以在没有数据或内存被锁定时立即返回错误信息，而不是阻塞该进程，这依赖于文件或管道的打开模式。反之，进程可以休眠在索引节点的等待队列中等待写入进程写入数据。当所有的进程完成了管道操作之后，管道的索引节点被丢弃，而共享数据页也被释放。

Linux函数原型:

#include <unistd.h>
int pipe(int filedes[2]);
filedes[0]用于读出数据，读取时必须关闭写入端，即close(filedes[1]);

filedes[1]用于写入数据，写入时必须关闭读取端，即close(filedes[0])。

程序实例：

int main(void)
{
    int n;
    int fd[2];
    pid_t pid;
    char line[MAXLINE];

    if(pipe(fd)  0){                 /* 先建立管道得到一对文件描述符 */
        exit(0);
    }

    if((pid = fork())  0)            /* 父进程把文件描述符复制给子进程 */
        exit(1);
    else if(pid > 0){                /* 父进程写 */
        close(fd[0]);                /* 关闭读描述符 */
        write(fd[1], "\nhello world\n", 14);
    }
    else{                            /* 子进程读 */
        close(fd[1]);                /* 关闭写端 */
        n = read(fd[0], line, MAXLINE);
        write(STDOUT_FILENO, line, n);
    }

    exit(0);
}
命名管道(named PIPE)

由于基于fork机制，所以管道只能用于父进程和子进程之间，或者拥有相同祖先的两个子进程之间 (有亲缘关系的进程之间)。为了解决这一问题，Linux提供了FIFO方式连接进程。FIFO又叫做命名管道(named PIPE)。

FIFO (First in, First out)为一种特殊的文件类型，它在文件系统中有对应的路径。当一个进程以读(r)的方式打开该文件，而另一个进程以写(w)的方式打开该文件，那么内核就会在这两个进程之间建立管道，所以FIFO实际上也由内核管理，不与硬盘打交道。之所以叫FIFO，是因为管道本质上是一个先进先出的队列数据结构，最早放入的数据被最先读出来，从而保证信息交流的顺序。FIFO只是借用了文件系统(file system,命名管道是一种特殊类型的文件，因为Linux中所有事物都是文件，它在文件系统中以文件名的形式存在。)来为管道命名。写模式的进程向FIFO文件中写入，而读模式的进程从FIFO文件中读出。当删除FIFO文件时，管道连接也随之消失。FIFO的好处在于我们可以通过文件的路径来识别管道，从而让没有亲缘关系的进程之间建立连接

函数原型：

#include <sys/types.h>
#include <sys/stat.h>

int mkfifo(const char *filename, mode_t mode);
int mknode(const char *filename, mode_t mode | S_IFIFO, (dev_t) 0 );
其中pathname是被创建的文件名称，mode表示将在该文件上设置的权限位和将被创建的文件类型(在此情况下为S_IFIFO)，dev是当创建设备特殊文件时使用的一个值。因此，对于先进先出文件它的值为0。

** 程序实例：**

#include <stdio.h>  
#include <stdlib.h>  
#include <sys/types.h>  
#include <sys/stat.h>  

int main()  
{  
    int res = mkfifo("/tmp/my_fifo", 0777);  
    if (res == 0)  
    {  
        printf("FIFO created/n");  
    }  
     exit(EXIT_SUCCESS);  
}
编译这个程序：

gcc –o fifo1.c fifo

运行这个程序：

$ ./fifo1

用ls命令查看所创建的管道

$ ls -lF /tmp/my_fifo
prwxr-xr-x 1 root root 0 05-08 20:10 /tmp/my_fifo|

注意：ls命令的输出结果中的第一个字符为p，表示这是一个管道。最后的|符号是由ls命令的-F选项添加的，它也表示是这是一个管道。

FIFO读写规则

从FIFO中读取数据： 约定：如果一个进程为了从FIFO中读取数据而阻塞打开了FIFO，那么称该进程内的读操作为设置了阻塞标志的读操作

从FIFO中写入数据： 约定：如果一个进程为了向FIFO中写入数据而阻塞打开FIFO，那么称该进程内的写操作为设置了阻塞标志的写操作。

详见：http://blog.csdn.net/MONKEY_D_MENG/article/details/5570468

信号（Signal）

信号是比较复杂的通信方式，用于通知接受进程有某种事件发生，除了用于进程间通信外，进程还可以发送信号给进程本身；Linux除了支持Unix早期信号语义函数sigal外，还支持语义符合Posix.1标准的信号函数sigaction（实际上，该函数是基于BSD的，BSD为了实现可靠信号机制，又能够统一对外接口，用sigaction函数重新实现了signal函数）

信号种类

信号种类

每种信号类型都有对应的信号处理程序(也叫信号的操作)，就好像每个中断都有一个中断服务例程一样。大多数信号的默认操作是结束接收信号的进程；然而，一个进程通常可以请求系统采取某些代替的操作，各种代替操作是：

忽略信号。随着这一选项的设置，进程将忽略信号的出现。有两个信号 不可以被忽略：SIGKILL，它将结束进程；SIGSTOP，它是作业控制机制的一部分，将挂起作业的执行。
恢复信号的默认操作。
执行一个预先安排的信号处理函数。进程可以登记特殊的信号处理函数。当进程收到信号时，信号处理函数将像中断服务例程一样被调用，当从该信号处理函数返回时，控制被返回给主程序，并且继续正常执行。
但是，信号和中断有所不同。中断的响应和处理都发生在内核空间，而信号的响应发生在内核空间，信号处理程序的执行却发生在用户空间。

那么，什么时候检测和响应信号呢？通常发生在两种情况下：

当前进程由于系统调用、中断或异常而进入内核空间以后，从内核空间返回到用户空间前夕；
当前进程在内核中进入睡眠以后刚被唤醒的时候，由于检测到信号的存在而提前返回到用户空间。
函数原型等详见：http://www.cnblogs.com/biyeymyhjob/archive/2012/08/04/2622265.html

信号本质

信号是在软件层次上对中断机制的一种模拟，在原理上，一个进程收到一个信号与处理器收到一个中断请求可以说是一样的。信号是异步的，一个进程不必通过任何操作来等待信号的到达，事实上，进程也不知道信号到底什么时候到达。

信号是进程间通信机制中唯一的异步通信机制，可以看作是异步通知，通知接收信号的进程有哪些事情发生了。信号机制经过POSIX实时扩展后，功能更加强大，除了基本通知功能外，还可以传递附加信息。

信号来源

信号事件的发生有两个来源：硬件来源(比如我们按下了键盘或者其它硬件故障)；软件来源，最常用发送信号的系统函数是kill, raise, alarm和setitimer以及sigqueue函数，软件来源还包括一些非法运算等操作。

关于信号处理机制的原理(内核角度)

内核给一个进程发送软中断信号的方法，是在进程所在的进程表项的信号域设置对应于该信号的位。这里要补充的是，如果信号发送给一个正在睡眠的进程，那么要 看该进程进入睡眠的优先级，如果进程睡眠在可被中断的优先级上，则唤醒进程；否则仅设置进程表中信号域相应的位，而不唤醒进程。这一点比较重要，因为进程检查是否收到信号的时机是：一个进程在即将从内核态返回到用户态时；或者，在一个进程要进入或离开一个适当的低调度优先级睡眠状态时。

内核处理一个进程收到的信号的时机是在一个进程从内核态返回用户态时。所以，当一个进程在内核态下运行时，软中断信号并不立即起作用，要等到将返回用户态时才处理。进程只有处理完信号才会返回用户态（上面的例子程序中，在步骤5中，解除阻塞后，先打印caught SIGQUIT，再打印SIGQUIT unblocked，即在sigprocmask返回前，信号处理程序先执行），进程在用户态下不会有未处理完的信号。

内核处理一个进程收到的软中断信号是在该进程的上下文中，因此，进程必须处于运行状态。如果进程收到一个要捕捉的信号，那么进程从内核态返回用户态时执行用户定义的函数。而且执行用户定义的函数的方法很巧妙，内核是在用户栈上创建一个新的层，该层中将返回地址的值设置成用户定义的处理函数的地址，这样进程从内核返回弹出栈顶时就返回到用户定义的函数处，从函数返回再弹出栈顶时，才返回原先进入内核的地方，接着原来的地方继续运行。这样做的原因是用户定义的处理函数不能且不允许在内核态下执行（如果用户定义的函数在内核态下运行的话，用户就可以获得任何权限）。

在信号的处理方法中有几点特别要引起注意。

第一，在一些系统中，当一个进程处理完中断信号返回用户态之前，内核清除用户区中设定的对该信号的处理例程的地址，即下一次进程对该信号的处理方法又改为默认值，除非在下一次信号到来之前再次使用signal系统调用。这可能会使得进程在调用signal之前又得 到该信号而导致退出。在BSD中，内核不再清除该地址。但不清除该地址可能使得进程因为过多过快的得到某个信号而导致堆栈溢出。为了避免出现上述情况。在 BSD系统中，内核模拟了对硬件中断的处理方法，即在处理某个中断时，阻止接收新的该类中断。

第二个要引起注意的是，如果要捕捉的信号发生于进程正在一个系统调用中时，并且该进程睡眠在可中断的优先级上（若系统调用未睡眠而是在运行，根据上面的分 析，等该系统调用运行完毕后再处理信号），这时该信号引起进程作一次longjmp，跳出睡眠状态，返回用户态并执行信号处理例程。当从信号处理例程返回 时，进程就象从系统调用返回一样，但返回了一个错误如－1，并将errno设置为EINTR，指出该次系统调用曾经被中断。这要注意的是，BSD系统中内 核可以自动地重新开始系统调用，或者手如上面所述手动设置重启。

第三个要注意的地方：若进程睡眠在可中断的优先级上，则当它收到一个要忽略的信号时，该进程被唤醒，但不做longjmp，一般是继续睡眠。但用户感觉不 到进程曾经被唤醒，而是象没有发生过该信号一样。所以能够使pause、sleep等函数从挂起态返回的信号必须要有信号处理函数，如果没有什么动作，可 以将处理函数设为空。

第四个要注意的地方：内核对子进程终止（SIGCLD）信号的处理方法与其他信号有所区别。当进程正常或异常终止时，内核都向其父进程发一个SIGCLD 信号，缺省情况下，父进程忽略该信号，就象没有收到该信号似的，如果父进程希望获得子进程终止的状态，则应该事先用signal函数为SIGCLD信号设 置信号处理程序，在信号处理程序中调用wait。

SIGCLD信号的作用是唤醒一个睡眠在可被中断优先级上的进程。如果该进程捕捉了这个信号，就象普通信号处理一样转到处理例程。如果进程忽略该信号，则 什么也不做。其实wait不一定放在信号处理函数中，但这样的话因为不知道子进程何时终止，在子进程终止前，wait将使父进程挂起休眠。

信号生命周期

信号生命周期

参考

https://www.cnblogs.com/biyeymyhjob/archive/2012/11/03/2751593.html
http://www.cnblogs.com/vamei/archive/2012/10/10/2715398.html
http://bbs.chinaunix.net/thread-1947211-1-1.html

第 8 页（共 13 页）
记得刚毕业那会参加面试，面试官会问我 Redis 为什么快，由于当时技术水平有限，我只能回答出如下两点：

数据是存储在内存中的。
Redis 是单线程的。
当然，将数据存储在内存中，读取的时候不需要进行磁盘的 IO，单线程也保证了系统没有线程的上下文切换。

但这两点只是 Redis 高性能原因的很小一部分，下面从数据存储层面上为大家分析 Redis 性能为何如此高。

Redis性能如此高的原因，我总结了如下几点：

纯内存操作
单线程
高效的数据结构
合理的数据编码
其他方面的优化
在 Redis 中，常用的 5 种数据结构和应用场景如下：

String：缓存、计数器、分布式锁等。
List：链表、队列、微博关注人时间轴列表等。
Hash：用户信息、Hash 表等。
Set：去重、赞、踩、共同好友等。
Zset：访问量排行榜、点击量排行榜等。
SDS
字符串

Redis 是用 C 语言开发完成的，但在 Redis 字符串中，并没有使用 C 语言中的字符串，而是用一种称为 SDS（Simple Dynamic String）的结构体来保存字符串。

SDS示例

struct sdshdr {
      int len;
    int free;
    char buf[];
}
SDS 的结构如上图：

len：用于记录 buf 中已使用空间的长度。
free：buf 中空闲空间的长度。
buf[]：存储实际内容。
例如：执行命令 set key value，key 和 value 都是一个 SDS 类型的结构存储在内存中。

SDS 与 C 字符串的区别

①常数时间内获得字符串长度

C 字符串本身不记录长度信息，每次获取长度信息都需要遍历整个字符串，复杂度为 O(n)；C 字符串遍历时遇到'\0‘ 时结束。

SDS 中 len 字段保存着字符串的长度，所以总能在常数时间内获取字符串长度，复杂度是 O(1)。

②避免缓冲区溢出

假设在内存中有两个紧挨着的两个字符串，s1="xxxxx"和 s2="yyyyy"。

由于在内存上紧紧相连，当我们对 s1 进行扩充的时候，将 s1=“xxxxxzzzzz”后，由于没有进行相应的内存重新分配，导致 s1 把 s2 覆盖掉，导致 s2 被莫名其妙的修改。

但 SDS 的 API 对 zfc 修改时首先会检查空间是否足够，若不充足则会分配新空间，避免了缓冲区溢出问题。

③减少字符串修改时带来的内存重新分配的次数

在 C 中，当我们频繁的对一个字符串进行修改（append 或 trim）操作的时候，需要频繁的进行内存重新分配的操作，十分影响性能。

如果不小心忘记，有可能会导致内存溢出或内存泄漏，对于 Redis 来说，本身就会很频繁的修改字符串，所以使用 C 字符串并不合适。而 SDS 实现了空间预分配和惰性空间释放两种优化策略：

空间预分配：当 SDS 的 API 对一个 SDS 修改后，并且对 SDS 空间扩充时，程序不仅会为 SDS 分配所需要的必须空间，还会分配额外的未使用空间。

分配规则如下：如果对 SDS 修改后，len 的长度小于 1M，那么程序将分配和 len 相同长度的未使用空间。举个例子，如果 len=10，重新分配后，buf 的实际长度会变为 10(已使用空间)+10(额外空间)+1(空字符)=21。如果对 SDS 修改后 len 长度大于 1M，那么程序将分配 1M 的未使用空间。

惰性空间释放：当对 SDS 进行缩短操作时，程序并不会回收多余的内存空间，而是使用 free 字段将这些字节数量记录下来不释放，后面如果需要 append 操作，则直接使用 free 中未使用的空间，减少了内存的分配。

④二进制安全

在 Redis 中不仅可以存储 String 类型的数据，也可能存储一些二进制数据。

二进制数据并不是规则的字符串格式，其中会包含一些特殊的字符如 ‘\0’，在 C 中遇到 '\0' 则表示字符串的结束，但在 SDS 中，标志字符串结束的是 len 属性。

字典

与 Java 中的 HashMap 类似，Redis 中的 Hash 比 Java 中的更高级一些。

Redis 本身就是 KV 服务器，除了 Redis 本身数据库之外，字典也是哈希键的底层实现。

字典的数据结构如下所示：

typedef struct dict{
      dictType *type;
    void *privdata;
    dictht ht[2];
    int trehashidx;
}


typedef struct dictht{
    //哈希表数组
    dectEntrt **table;
    //哈希表大小
    unsigned long size;
    //
    unsigned long sizemask;
    //哈希表已有节点数量
    unsigned long used;
}
重要的两个字段是 dictht 和 trehashidx，这两个字段与 rehash 有关，下面重点介绍 rehash。

Rehash

学过 Java 的朋友都应该知道 HashMap 是如何 rehash 的，在此处我就不过多赘述，下面介绍 Redis 中 Rehash 的过程。

由上段代码，我们可知 dict 中存储了一个 dictht 的数组，长度为 2，表明这个数据结构中实际存储着两个哈希表 ht[0] 和 ht[1]，为什么要存储两张 hash 表呢？

当然是为了 Rehash，Rehash 的过程如下：

为 ht[1] 分配空间。如果是扩容操作，ht[1] 的大小为第一个大于等于 ht[0].used*2 的 2^n；如果是缩容操作，ht[1] 的大小为第一个大于等于 ht[0].used 的 2^n。
将 ht[0] 中的键值 Rehash 到 ht[1] 中。
当 ht[0] 全部迁移到 ht[1] 中后，释放 ht[0]，将 ht[1] 置为 ht[0]，并为 ht[1] 创建一张新表，为下次 Rehash 做准备。
渐进式 Rehash

由于 Redis 的 Rehash 操作是将 ht[0] 中的键值全部迁移到 ht[1]，如果数据量小，则迁移过程很快。但如果数据量很大，一个 Hash 表中存储了几万甚至几百万几千万的键值时，迁移过程很慢并会影响到其他用户的使用。

为了避免 Rehash 对服务器性能造成影响，Redis 采用了一种渐进式 Rehash 的策略，分多次、渐进的将 ht[0] 中的数据迁移到 ht[1] 中。

前一过程如下：

为 ht[1] 分配空间，让字典同时拥有 ht[0] 和 ht[1] 两个哈希表。
字典中维护一个 rehashidx，并将它置为 0，表示 Rehash 开始。
在 Rehash 期间，每次对字典操作时，程序还顺便将 ht[0] 在 rehashidx 索引上的所有键值对 rehash 到 ht[1] 中，当 Rehash 完成后，将 rehashidx 属性+1。当全部 rehash 完成后，将 rehashidx 置为 -1，表示 rehash 完成。
注意，由于维护了两张 Hash 表，所以在 Rehash 的过程中内存会增长。另外，在 Rehash 过程中，字典会同时使用 ht[0] 和 ht[1]。

所以在删除、查找、更新时会在两张表中操作，在查询时会现在第一张表中查询，如果第一张表中没有，则会在第二张表中查询。但新增时一律会在 ht[1] 中进行，确保 ht[0] 中的数据只会减少不会增加。

跳跃表

Zset 是一个有序的链表结构，其底层的数据结构是跳跃表 skiplist，其结构如下：

typedef struct zskiplistNode {
    //成员对象
   robj *obj;
    //分值
   double score;
    //后退指针
   struct zskiplistNode *backward;
    //层
   struct zskiplistLevel {
        struct zskiplistNode *forward;//前进指针
        unsigned int span;//跨度
   } level[];
 } zskiplistNode;
typedef struct zskiplist {
    //表头节点和表尾节点
   struct zskiplistNode *header, *tail;
    //表中节点的的数量
   unsigned long length;
    //表中层数最大的节点层数
   int level;
 } zskiplist;
一个跳跃表

前进指针：用于从表头向表尾方向遍历。

后退指针：用于从表尾向表头方向回退一个节点，和前进指针不同的是，前进指针可以一次性跳跃多个节点，后退指针每次只能后退到上一个节点。

跨度：表示当前节点和下一个节点的距离，跨度越大，两个节点中间相隔的元素越多。

在查询过程中跳跃着前进。由于存在后退指针，如果查询时超出了范围，通过后退指针回退到上一个节点后仍可以继续向前遍历。

压缩列表

压缩列表 ziplist 是为 Redis 节约内存而开发的，是列表键和字典键的底层实现之一。

当元素个数较少时，Redis 用 ziplist 来存储数据，当元素个数超过某个值时，链表键中会把 ziplist 转化为 linkedlist，字典键中会把 ziplist 转化为 hashtable。

ziplist 是由一系列特殊编码的连续内存块组成的顺序型的数据结构，ziplist 中可以包含多个 entry 节点，每个节点可以存放整数或者字符串。

压缩列表的各个组成部分

由于内存是连续分配的，所以遍历速度很快。

编码转化

Redis 使用对象（redisObject）来表示数据库中的键值，当我们在 Redis 中创建一个键值对时，至少创建两个对象，一个对象是用做键值对的键对象，另一个是键值对的值对象。

例如我们执行 SET MSG XXX 时，键值对的键是一个包含了字符串“MSG“的对象，键值对的值对象是包含字符串”XXX”的对象。

redisObject 的结构如下：

typedef struct redisObject{
    //类型
   unsigned type:4;
   //编码
   unsigned encoding:4;
   //指向底层数据结构的指针
   void *ptr;
    //...
 }robj;
其中 type 字段记录了对象的类型，包含字符串对象、列表对象、哈希对象、集合对象、有序集合对象。

当我们执行 type key 命令时返回的结果如下：

执行结果

ptr 指针字段指向对象底层实现的数据结构，而这些数据结构是由 encoding 字段决定的，每种对象至少有两种数据编码：



可以通过 object encoding key 来查看对象所使用的编码：



细心的读者可能注意到，list、hash、zset 三个键使用的是 ziplist 压缩列表编码，这就涉及到了 Redis 底层的编码转换。

上面介绍到，ziplist 是一种结构紧凑的数据结构，当某一键值中所包含的元素较少时，会优先存储在 ziplist 中，当元素个数超过某一值后，才将 ziplist 转化为标准存储结构，而这一值是可配置的。

String 对象的编码转化

String 对象的编码可以是 int 或 raw，对于 String 类型的键值，如果我们存储的是纯数字，Redis 底层采用的是 int 类型的编码，如果其中包括非数字，则会立即转为 raw 编码：

127.0.0.1:6379> set str 1
OK
127.0.0.1:6379> object encoding str
"int"
127.0.0.1:6379> set str 1a
OK
127.0.0.1:6379> object encoding str
"raw"
127.0.0.1:6379>
List 对象的编码转化

List 对象的编码可以是ziplist 或 linkedlist，对于 List 类型的键值，当列表对象同时满足以下两个条件时，采用 ziplist 编码：

列表对象保存的所有字符串元素的长度都小于 64 字节。
列表对象保存的元素个数小于 512 个。
如果不满足这两个条件的任意一个，就会转化为 linkedlist 编码。注意：这两个条件是可以修改的，在 redis.conf 中：

list-max-ziplist-entries 512
list-max-ziplist-value 64
Set 类型的编码转化

Set 对象的编码可以是 intset 或 hashtable，intset 编码的结构对象使用整数集合作为底层实现，把所有元素都保存在一个整数集合里面。

127.0.0.1:6379> sadd set 1 2 3
(integer) 3
127.0.0.1:6379> object encoding set
"intset"
127.0.0.1:6379>
如果 set 集合中保存了非整数类型的数据时，Redis 会将 intset 转化为 hashtable：

127.0.0.1:6379> sadd set 1 2 3
(integer) 3
127.0.0.1:6379> object encoding set
"intset"
127.0.0.1:6379> sadd set a
(integer) 1
127.0.0.1:6379> object encoding set
"hashtable"
 127.0.0.1:6379>
当 Set 对象同时满足以下两个条件时，对象采用 intset 编码：

保存的所有元素都是整数值（小数不行）。
Set 对象保存的所有元素个数小于 512 个。
不能满足这两个条件的任意一个，Set 都会采用 hashtable 存储。注意：第两个条件是可以修改的，在 redis.conf 中：

set-max-intset-entries 512
Hash 对象的编码转化

Hash 对象的编码可以是 ziplist 或 hashtable，当 Hash 以 ziplist 编码存储的时候，保存同一键值对的两个节点总是紧挨在一起，键节点在前，值节点在后：



当 Hash 对象同时满足以下两个条件时，Hash 对象采用 ziplist 编码：

Hash 对象保存的所有键值对的键和值的字符串长度均小于 64 字节。
Hash 对象保存的键值对数量小于 512 个。
如果不满足以上条件的任意一个，ziplist 就会转化为 hashtable 编码。注意：这两个条件是可以修改的，在 redis.conf 中：

hash-max-ziplist-entries 512
hash-max-ziplist-value 64
Zset 对象的编码转化

Zset 对象的编码可以是 ziplist 或 zkiplist，当采用 ziplist 编码存储时，每个集合元素使用两个紧挨在一起的压缩列表来存储。

第一个节点存储元素的成员，第二个节点存储元素的分值，并且按分值大小从小到大有序排列。



当 Zset 对象同时满足一下两个条件时，采用 ziplist 编码：

Zset 保存的元素个数小于 128。
Zset 元素的成员长度都小于 64 字节。
如果不满足以上条件的任意一个，ziplist 就会转化为 zkiplist 编码。注意：这两个条件是可以修改的，在 redis.conf 中：

zset-max-ziplist-entries 128
zset-max-ziplist-value 64
思考：Zset 如何做到 O(1) 复杂度内元素并且快速进行范围操作？Zset 采用 skiplist 编码时使用 zset 结构作为底层实现，该数据结构同时包含了一个跳跃表和一个字典。

其结构如下：

typedef struct zset{
    zskiplist *zsl;
   dict *dict;
}
Zset 中的 dict 字典为集合创建了一个从成员到分值之间的映射，字典中的键保存了成员，字典中的值保存了成员的分值，这样定位元素时时间复杂度是 O(1)。

Zset 中的 zsl 跳跃表适合范围操作，比如 ZRANK、ZRANGE 等，程序使用 zkiplist。

另外，虽然 Zset 中使用了 dict 和 skiplist 存储数据，但这两种数据结构都会通过指针来共享相同的内存，所以没有必要担心内存的浪费。

过期数据的删除对 Redis 性能影响

当我们对某些 key 设置了 expire 时，数据到了时间会自动删除。如果一个键过期了，它会在什么时候删除呢？

下面介绍三种删除策略：

定时删除：在这是键的过期时间的同时，创建一个定时器 Timer，让定时器在键过期时间来临时立即执行对过期键的删除。
惰性删除：键过期后不管，每次读取该键时，判断该键是否过期，如果过期删除该键返回空。
定期删除：每隔一段时间对数据库中的过期键进行一次检查。
定时删除：对内存友好，对 CPU 不友好。如果过期删除的键比较多的时候，删除键这一行为会占用相当一部分 CPU 性能，会对 Redis 的吞吐量造成一定影响。

惰性删除： 对 CPU 友好，内存不友好。如果很多键过期了，但在将来很长一段时间内没有很多客户端访问该键导致过期键不会被删除，占用大量内存空间。

定期删除： 是定时删除和惰性删除的一种折中。每隔一段时间执行一次删除过期键的操作，并且限制删除操作执行的时长和频率。

具体的操作如下：

Redis 会将每一个设置了 expire 的键存储在一个独立的字典中，以后会定时遍历这个字典来删除过期的 key。除了定时遍历外，它还会使用惰性删除策略来删除过期的 key。
Redis 默认每秒进行十次过期扫描，过期扫描不会扫描所有过期字典中的 key，而是采用了一种简单的贪心策略。
从过期字典中随机选择 20 个 key；删除这 20 个 key 中已过期的 key；如果过期 key 比例超过 1/4，那就重复步骤 1。
同时，为了保证在过期扫描期间不会出现过度循环，导致线程卡死，算法还增加了扫描时间上限，默认不会超过 25ms。
总结

总而言之，Redis 为了高性能，从各方各面都进行了优化，下次小伙伴们面试的时候，面试官问 Redis 性能为什么如此高，可不能傻傻的只说单线程和内存存储了。

第 9 页（共 13 页）
数组和切片是 Go 语言中常见的数据结构，很多刚刚使用 Go 的开发者往往会混淆这两个概念，数组作为最常见的集合在编程语言中是非常重要的，除了数组之外，Go 语言引入了另一个概念 — 切片，切片与数组有一些类似，但是它们的不同之处导致使用上会产生巨大的差别。

这里我们将从 Go 语言 编译期间 的工作和运行时来介绍数组以及切片的底层实现原理，其中会包括数组的初始化以及访问、切片的结构和常见的基本操作。

数组

数组是由相同类型元素的集合组成的数据结构，计算机会为数组分配一块连续的内存来保存数组中的元素，我们可以利用数组中元素的索引快速访问元素对应的存储地址，常见的数组大多都是一维的线性数组，而多维数组在数值和图形计算领域却有比较常见的应用。

Golang 数组结构

数组作为一种数据类型，一般情况下由两部分组成，其中一部分表示了数组中存储的元素类型，另一部分表示数组最大能够存储的元素个数，Go 语言的数组类型一般是这样的：

[10]int
[200]interface{}
Go 语言中数组的大小在初始化之后就无法改变，数组存储元素的类型相同，但是大小不同的数组类型在 Go 语言看来也是完全不同的，只有两个条件都相同才是同一个类型。

func NewArray(elem *Type, bound int64) *Type {
    if bound < 0 {
        Fatalf("NewArray: invalid bound %v", bound)
    }
    t := New(TARRAY)
    t.Extra = &Array{Elem: elem, Bound: bound}
    t.SetNotInHeap(elem.NotInHeap())
    return t
}
编译期间的数组类型 Array 就包含两个结构，一个是元素类型 Elem，另一个是数组的大小上限 Bound，这两个字段构成了数组类型，而当前数组是否应该在堆栈中初始化也在编译期间就确定了。

创建

Go 语言中的数组有两种不同的创建方式，一种是我们显式指定数组的大小，另一种是编译器通过源代码自行推断数组的大小：

arr1 := [3]int{1, 2, 3}
arr2 := [...]int{1, 2, 3}
后一种声明方式在编译期间就会被『转换』成为前一种，下面我们先来介绍数组大小的编译期推导过程。

上限推导

这两种不同的方式会导致编译器做出不同的处理，如果我们使用第一种方式 [10]T，那么变量的类型在编译进行到 类型检查 阶段就会被推断出来，在这时编译器会使用 NewArray 创建包含数组大小的 Array 类型，而如果使用 […]T 的方式，虽然在这一步也会创建一个 Array 类型 Array{Elem: elem, Bound: -1}，但是其中的数组大小上限会是 -1 的结构，这意味着还需要后面的 typecheckcomplit 函数推导该数组的大小：

func typecheckcomplit(n *Node) (res *Node) {
    // ...

    switch t.Etype {
    case TARRAY, TSLICE:
        var length, i int64
        nl := n.List.Slice()
        for i2, l := range nl {
            i++
            if i > length {
                length = i
            }
        }

        if t.IsDDDArray() {
            t.SetNumElem(length)
        }
    }
}
这个删减后的 typecheckcomplit 函数通过遍历元素来推导当前数组的长度，我们能看出 […]T 类型的声明不是在运行时被推导的，它会在类型检查期间就被推断出正确的数组大小。

语句转换

虽然 [...]T{1, 2, 3}和 [3]T{1, 2, 3} 在运行时是完全等价的，但是这种简短的初始化方式也只是 Go 语言为我们提供的一种语法糖，对于一个由字面量组成的数组，根据数组元素数量的不同，编译器会在负责初始化字面量的 anylit 函数中做两种不同的优化：

func anylit(n *Node, var_ *Node, init *Nodes) {
    t := n.Type
    switch n.Op {
    case OSTRUCTLIT, OARRAYLIT:
        if n.List.Len() > 4 {
            vstat := staticname(t)
            vstat.Name.SetReadonly(true)

            fixedlit(inNonInitFunction, initKindStatic, n, vstat, init)

            a := nod(OAS, var_, vstat)
            a = typecheck(a, ctxStmt)
            a = walkexpr(a, init)
            init.Append(a)
            break
        }


        fixedlit(inInitFunction, initKindLocalCode, n, var_, init)
    // ...
    }
}
当元素数量小于或者等于 4 个时，会直接将数组中的元素放置在栈上；
当元素数量大于 4 个时，会将数组中的元素放置到静态区并在运行时取出；
当数组的元素小于或者等于四个时，fixedlit 会负责在函数编译之前将批了语法糖外衣的代码转换成原有的样子：

func fixedlit(ctxt initContext, kind initKind, n *Node, var_ *Node, init *Nodes) {
    var splitnode func(*Node) (a *Node, value *Node)
    // ...

    for _, r := range n.List.Slice() {
        a, value := splitnode(r)

        a = nod(OAS, a, value)
        a = typecheck(a, ctxStmt)
        switch kind {
        case initKindStatic:
            genAsStatic(a)
        case initKindLocalCode:
            a = orderStmtInPlace(a, map[string][]*Node{})
            a = walkstmt(a)
            init.Append(a)
        default:
            Fatalf("fixedlit: bad kind %d", kind)
        }
    }
}
由于传入的类型是 initKindLocalCode，上述代码会将原有的初始化语法拆分成一个声明变量的语句和 N 个用于赋值的语句：

var arr [3]int
arr[0] = 1
arr[1] = 2
arr[2] = 3
但是如果当前数组的元素大于 4 个时，anylit 方法会先获取一个唯一的 staticname，然后调用 fixedlit 函数在静态存储区初始化数组中的元素并将临时变量赋值给当前的数组：

func fixedlit(ctxt initContext, kind initKind, n *Node, var_ *Node, init *Nodes) {
    var splitnode func(*Node) (a *Node, value *Node)
    // ...

    for _, r := range n.List.Slice() {
        a, value := splitnode(r)

        setlineno(value)
        a = nod(OAS, a, value)
        a = typecheck(a, ctxStmt)
        switch kind {
        case initKindStatic:
            genAsStatic(a)
        default:
            Fatalf("fixedlit: bad kind %d", kind)
        }

    }
}
假设，我们在代码中初始化 []int{1, 2, 3, 4, 5} 数组，那么我们可以将上述过程理解成以下的伪代码：

var arr [5]int
statictmp_0[0] = 1
statictmp_0[1] = 2
statictmp_0[2] = 3
statictmp_0[3] = 4
statictmp_0[4] = 5
arr = statictmp_0
总结起来，如果数组中元素的个数小于或者等于 4 个，那么所有的变量会直接在栈上初始化，如果数组元素大于 4 个，变量就会在静态存储区初始化然后拷贝到栈上，这些转换后的代码才会继续进入 中间代码生成 和 机器码生成 两个阶段，最后生成可以执行的二进制文件。

访问和赋值

无论是在栈上还是静态存储区，数组在内存中其实就是一连串的内存空间，表示数组的方法就是一个指向数组开头的指针，这一片内存空间不知道自己存储的是什么变量：

golang数组访问和赋值

数组访问越界的判断也都是在编译期间由静态类型检查完成的，typecheck1 函数会对访问的数组索引进行验证：

func typecheck1(n *Node, top int) (res *Node) {
    switch n.Op {
    case OINDEX:
        ok |= ctxExpr
        l := n.Left
        r := n.Right
        t := l.Type
        switch t.Etype {
        case TSTRING, TARRAY, TSLICE:
            why := "string"
            if t.IsArray() {
                why = "array"
            } else if t.IsSlice() {
                why = "slice"
            }

            if n.Right.Type != nil && !n.Right.Type.IsInteger() {
                yyerror("non-integer %s index %v", why, n.Right)
                break
            }

            if !n.Bounded() && Isconst(n.Right, CTINT) {
                x := n.Right.Int64()
                if x < 0 {
                    yyerror("invalid %s index %v (index must be non-negative)", why, n.Right)
                } else if t.IsArray() && x >= t.NumElem() {
                    yyerror("invalid array index %v (out of bounds for %d-element array)", n.Right, t.NumElem())
                } else if Isconst(n.Left, CTSTR) && x >= int64(len(n.Left.Val().U.(string))) {
                    yyerror("invalid string index %v (out of bounds for %d-byte string)", n.Right, len(n.Left.Val().U.(string)))
                }
            }
        }
    //...
    }
}
无论是编译器还是字符串，它们的越界错误都会在编译期间发现，但是数组访问操作 OINDEX 会在编译期间被转换成两个 SSA 指令：

PtrIndex <t> ptr idx
Load <t> ptr mem
编译器会先获取数组的内存地址和访问的下标，然后利用 PtrIndex 计算出目标元素的地址，再使用 Load 操作将指针中的元素加载到内存中。

数组的赋值和更新操作 a[i] = 2 也会生成 SSA 期间就计算出数组当前元素的内存地址，然后修改当前内存地址的内容，其实会被转换成如下所示的 SSA 操作：

LocalAddr {sym} base _
PtrIndex <t> ptr idx
Store {t} ptr val mem
在这个过程中会确实能够目标数组的地址，再通过 PtrIndex 获取目标元素的地址，最后将数据存入地址中，从这里我们可以看出无论是数组的寻址还是赋值都是在编译阶段完成的，没有运行时的参与。

切片

数组其实在 Go 语言中没有那么常用，更加常见的数据结构其实是切片，切片其实就是动态数组，它的长度并不固定，可以追加元素并会在切片容量不足时进行扩容。

在 Golang 中，切片类型的声明与数组有一些相似，由于切片是『动态的』，它的长度并不固定，所以声明类型时只需要指定切片中的元素类型：

[]int
[]interface{}
从这里的定义我们其实也能推测出，切片在编译期间的类型应该只会包含切片中的元素类型，NewSlice 就是编译期间用于创建 Slice 类型的函数：

func NewSlice(elem *Type) *Type {
    if t := elem.Cache.slice; t != nil {
        if t.Elem() != elem {
            Fatalf("elem mismatch")
        }
        return t
    }

    t := New(TSLICE)
    t.Extra = Slice{Elem: elem}
    elem.Cache.slice = t
    return t
}
我们可以看到上述方法返回的类型 TSLICE 的 Extra 字段是一个只包含切片内元素类型的 Slice{Elem: elem} 结构，也就是说切片内元素的类型是在编译期间确定的。

结构

编译期间的切片其实就是一个 Slice 类型，但是在运行时切片其实由如下的 SliceHeader 结构体表示，其中 Data 字段是一个指向数组的指针，Len 表示当前切片的长度，而 Cap 表示当前切片的容量，也就是 Data 数组的大小：

type SliceHeader struct {
    Data uintptr
    Len  int
    Cap  int
}
Data 作为一个指针指向的数组其实就是一片连续的内存空间，这片内存空间可以用于存储切片中保存的全部元素，数组其实就是一片连续的内存空间，数组中的元素只是逻辑上的概念，底层存储其实都是连续的，所以我们可以将切片理解成一片连续的内存空间加上长度与容量标识。

Golang切片结构

与数组不同，数组中大小、其中的元素还有对数组的访问和更新在编译期间就已经全部转换成了直接对内存的操作，但是切片是运行时才会确定的结构，所有的操作还需要依赖 Go 语言的运行时来完成，我们接下来就会介绍切片的一些常见操作的实现原理。

初始化

首先需要介绍的就是切片的创建过程，Go 语言中的切片总共有两种初始化的方式，一种是使用字面量初始化新的切片，另一种是使用关键字 make 创建切片：

slice := []int{1, 2, 3}
slice := make([]int, 10)
字面量

我们先来介绍如何使用字面量的方式创建新的切片结构，[]int{1, 2, 3} 其实会在编译期间由 slicelit 转换成如下所示的代码：

var vstat [3]int
vstat[0] = 1
vstat[1] = 2
vstat[2] = 3
var vauto *[3]int = new([3]int)
*vauto = vstat
slice := vauto[:]
根据切片中的元素数量对底层数组的大小进行推断并创建一个数组；
将这些字面量元素存储到初始化的数组中；
创建一个同样指向 [3]int 类型的数组指针；
将静态存储区的数组 vstat 赋值给 vauto 指针所在的地址；
通过 [:] 操作获取一个底层使用 vauto 的切片；
[:] 以及类似的操作 [:10] 其实都会在 SSA 代码生成 阶段被转换成 OpSliceMake 操作，这个操作会接受四个参数创建一个新的切片，切片元素类型、数组指针、切片大小和容量。

关键字

如果使用字面量的方式创建切片，大部分的工作就都会在编译期间完成，但是当我们使用 make 关键字创建切片时，在 类型检查 期间会检查 make『函数』的参数，调用方必须传入一个切片的大小以及可选的容量：

func typecheck1(n *Node, top int) (res *Node) {
    switch n.Op {
    // ...
    case OMAKE:
        args := n.List.Slice()

        i := 1
        switch t.Etype {
        case TSLICE:
            if i >= len(args) {
                yyerror("missing len argument to make(%v)", t)
                return n
            }

            l = args[i]
            i++
            var r *Node
            if i < len(args) {
                r = args[i]
            }

            // ...
            if Isconst(l, CTINT) && r != nil && Isconst(r, CTINT) && l.Val().U.(*Mpint).Cmp(r.Val().U.(*Mpint)) > 0 {
                yyerror("len larger than cap in make(%v)", t)
                return n
            }

            n.Left = l
            n.Right = r
            n.Op = OMAKESLICE
        }
    // ...
    }
}
make 参数的检查都是在 typecheck1 函数中完成的，它不仅会检查 len，而且会保证传入的容量 cap 一定大于或者等于 len；随后的中间代码生成阶段会把这里的 OMAKESLICE 类型的操作都转换成如下所示的函数调用：

makeslice(type, len, cap)
当切片的容量和大小不能使用 int 来表示时，就会实现 makeslice64 处理容量和大小更大的切片，无论是 makeslice 还是 makeslice64，这两个方法都是在结构逃逸到堆上初始化时才需要调用的，如果当前的切片不会发生逃逸并且切片非常小的时候，make([]int, 3, 4) 才会被转换成如下所示的代码：

var arr [4]int
n := arr[:3]
在这时，数组的初始化和 [:3] 操作就都会在编译阶段完成大部分的工作，前者会在静态存储区被创建，后者会被转换成 OpSliceMake 操作。

接下来，我们回到用于创建切片的 makeslice 函数，这个函数的实现其实非常简单：

func makeslice(et *_type, len, cap int) unsafe.Pointer {
    mem, overflow := math.MulUintptr(et.size, uintptr(cap))
    if overflow || mem > maxAlloc || len < 0 || len > cap {
        mem, overflow := math.MulUintptr(et.size, uintptr(len))
        if overflow || mem > maxAlloc || len < 0 {
            panicmakeslicelen()
        }
        panicmakeslicecap()
    }

    return mallocgc(mem, et, true)
}
上述代码的主要工作就是用切片中元素大小和切片容量相乘计算出切片占用的内存空间，如果内存空间的大小发生了溢出、申请的内存大于最大可分配的内存、传入的长度小于 0 或者长度大于容量，那么就会直接报错，当然大多数的错误都会在编译期间就检查出来，mallocgc 就是用于申请内存的函数，这个函数的实现还是比较复杂，如果遇到了比较小的对象会直接初始化在 Golang 调度器里面的 P 结构中，而大于 32KB 的一些对象会在堆上初始化。

初始化后会返回指向这片内存空间的指针，在之前版本的 Go 语言中，指针会和长度与容量一起被合成一个 slice 结构返回到 makeslice 的调用方，但是从 020a18c5 这个 commit 开始，构建结构体 SliceHeader 的工作就都由上层在类型检查期间完成了：

func typecheck1(n *Node, top int) (res *Node) {
    switch n.Op {
    // ...
    case OSLICEHEADER:
    switch 
        t := n.Type
        n.Left = typecheck(n.Left, ctxExpr)
        l := typecheck(n.List.First(), ctxExpr)
        c := typecheck(n.List.Second(), ctxExpr)
        l = defaultlit(l, types.Types[TINT])
        c = defaultlit(c, types.Types[TINT])

        n.List.SetFirst(l)
        n.List.SetSecond(c)
    // ...
    }
}
OSLICEHEADER 操作会创建一个如下所示的结构体，其中包含数组指针、切片长度和容量，它是切片在运行时的表示：

type SliceHeader struct {
    Data uintptr
    Len  int
    Cap  int
}
正是因为大多数对切片类型的操作并不需要直接操作原 slice 结构体，所以 SliceHeader 的引入能够减少切片初始化时的开销，这个改动能够减少 0.2% 的 Go 语言包大小并且能够减少 92 个 panicindex 的调用。

访问

对切片常见的操作就是获取它的长度或者容量，这两个不同的函数 len 和 cap 其实被 Go 语言的编译器看成是两种特殊的操作 OLEN 和 OCAP，它们会在 SSA 生成阶段 被转换成 OpSliceLen 和 OpSliceCap 操作：

func (s *state) expr(n *Node) *ssa.Value {
    switch n.Op {
    case OLEN, OCAP:
        switch {
        case n.Left.Type.IsSlice():
            op := ssa.OpSliceLen
            if n.Op == OCAP {
                op = ssa.OpSliceCap
            }
            return s.newValue1(op, types.Types[TINT], s.expr(n.Left))
        // ...
        }
    // ...
    }
}
除了获取切片的长度和容量之外，访问切片中元素使用的 OINDEX 操作也都在 SSA 中间代码生成期间就转换成对地址的获取操作：

func (s *state) expr(n *Node) *ssa.Value {
    switch n.Op {
    case OINDEX:
        switch {
        case n.Left.Type.IsSlice():
            p := s.addr(n, false)
            return s.load(n.Left.Type.Elem(), p)
        // ...
        }
    // ...
    }
}
切片的操作基本都是在编译期间完成的，除了访问切片的长度、容量或者其中的元素之外，使用 range 遍历切片时也是在编译期间被转换成了形式更简单的代码，我们会在后面的章节中介绍 range 关键字的实现原理。

追加

向切片中追加元素应该是最常见的切片操作，在 Go 语言中我们会使用 append 关键字向切片中追加元素，追加元素会根据是否 inplace 在中间代码生成阶段转换成以下的两种不同流程，如果 append 之后的切片不需要赋值回原有的变量，也就是如 append(slice, 1, 2, 3) 所示的表达式会被转换成如下的过程：

ptr, len, cap := slice
newlen := len + 3
if newlen > cap {
    ptr, len, cap = growslice(slice, newlen)
    newlen = len + 3
}
*(ptr+len) = 1
*(ptr+len+1) = 2
*(ptr+len+2) = 3
return makeslice(ptr, newlen, cap)
我们会先对切片结构体进行解构获取它的数组指针、大小和容量，如果新的切片大小大于容量，那么就会使用 growslice 对切片进行扩容并将新的元素依次加入切片并创建新的切片，但是 slice = apennd(slice, 1, 2, 3) 这种 inplace 的表达式就只会改变原来的 slice 变量：

a := &slice
ptr, len, cap := slice
newlen := len + 3
if uint(newlen) > uint(cap) {
   newptr, len, newcap = growslice(slice, newlen)
   vardef(a)
   *a.cap = newcap
   *a.ptr = newptr
}
newlen = len + 3
*a.len = newlen
*(ptr+len) = 1
*(ptr+len+1) = 2
*(ptr+len+2) = 3
上述两段代码的逻辑其实差不多，最大的区别在于最后的结果是不是赋值会原有的变量，不过从 inplace 的代码可以看出 Go 语言对类似的过程进行了优化，所以我们并不需要担心 append 会在数组容量足够时导致发生切片的复制。

Golang 切片追加

到这里我们已经了解了在切片容量足够时如何向切片中追加元素，但是如果切片的容量不足时就会调用 growslice 为切片扩容：

func growslice(et *_type, old slice, cap int) slice {
    newcap := old.cap
    doublecap := newcap + newcap
    if cap > doublecap {
        newcap = cap
    } else {
        if old.len < 1024 {
            newcap = doublecap
        } else {
            for 0 < newcap && newcap < cap {
                newcap += newcap / 4
            }
            if newcap <= 0 {
                newcap = cap
            }
        }
    }
扩容其实就是需要为切片分配一块新的内存空间，分配内存空间之前需要先确定新的切片容量，Go 语言根据切片的当前容量选择不同的策略进行扩容：

如果期望容量大于当前容量的两倍就会使用期望容量；
如果当前切片容量小于 1024 就会将容量翻倍；
如果当前切片容量大于 1024 就会每次增加 25% 的容量，直到新容量大于期望容量；
确定了切片的容量之后，我们就可以开始计算切片中新数组的内存占用了，计算的方法就是将目标容量和元素大小相乘：

    var overflow bool
    var lenmem, newlenmem, capmem uintptr
    switch {
    // ...
    default:
        lenmem = uintptr(old.len) * et.size
        newlenmem = uintptr(cap) * et.size
        capmem, overflow = math.MulUintptr(et.size, uintptr(newcap))
        capmem = roundupsize(capmem)
        newcap = int(capmem / et.size)
    }

    var p unsafe.Pointer
    if et.kind&kindNoPointers != 0 {
        p = mallocgc(capmem, nil, false)
        memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem)
    } else {
        p = mallocgc(capmem, et, true)
        if writeBarrier.enabled {
            bulkBarrierPreWriteSrcOnly(uintptr(p), uintptr(old.array), lenmem)
        }
    }
    memmove(p, old.array, lenmem)

    return slice{p, old.len, newcap}
}
如果当前切片中元素不是指针类型，那么就会调用 memclrNoHeapPointers 函数将超出当前长度的位置置空并在最后使用 memmove 将原数组内存中的内容拷贝到新申请的内存中， 不过无论是 memclrNoHeapPointers 还是 memmove 函数都使用目标机器上的汇编指令进行实现，例如 WebAssembly 使用如下的命令实现 memclrNoHeapPointers 函数：

TEXT runtime·memclrNoHeapPointers(SB), NOSPLIT, $0-16
    MOVD ptr+0(FP), R0
    MOVD n+8(FP), R1

loop:
    Loop
        Get R1
        I64Eqz
        If
            RET
        End

        Get R0
        I32WrapI64
        I64Const $0
        I64Store8 $0

        Get R0
        I64Const $1
        I64Add
        Set R0

        Get R1
        I64Const $1
        I64Sub
        Set R1

        Br loop
    End
    UNDEF
growslice 函数最终会返回一个新的 slice 结构，其中包含了新的数组指针、大小和容量，这个返回的三元组最终会改变原有的切片，帮助 append 完成元素追加的功能。

拷贝

切片的拷贝虽然不是一个常见的操作类型，但是却是我们学习切片实现原理必须要谈及的一个问题，当我们使用 copy(a, b) 的形式对切片进行拷贝时，编译期间会被转换成 slicecopy 函数：

func slicecopy(to, fm slice, width uintptr) int {
    if fm.len == 0 || to.len == 0 {
        return 0
    }

    n := fm.len
    if to.len < n {
        n = to.len
    }

    if width == 0 {
        return n
    }

    // ...

    size := uintptr(n) * width
    if size == 1 {
        *(*byte)(to.array) = *(*byte)(fm.array)
    } else {
        memmove(to.array, fm.array, size)
    }
    return n
}
上述函数的实现非常直接，它将切片中的全部元素通过 memmove 或者数组指针的方式将整块内存中的内容拷贝到目标的内存区域：



相比于依次对元素进行拷贝，这种方式能够提供更好的性能，但是需要注意的是，哪怕使用 memmove 对内存成块进行拷贝，但是这个操作还是会占用非常多的资源，在大切片上执行拷贝操作时一定要注意性能影响。

总结

数组和切片是 Go 语言中重要的数据结构，所以了解它们的实现能够帮助我们更好地理解这门语言，通过对它们实现的分析，我们知道了数组和切片的实现同时依赖编译器和运行时两部分。

数组的大多数操作在 编译期间 都会转换成对内存的直接读写；而切片的很多功能就都是在运行时实现的了，无论是初始化切片，还是对切片进行追加或扩容都需要运行时的支持，需要注意的是在遇到大切片扩容或者复制时可能会发生大规模的内存拷贝，一定要在使用时减少这种情况的发生避免对程序的性能造成影响。

Reference

Arrays, slices (and strings): The mechanics of ‘append’
Go Slices: usage and internals
Array vs Slice: accessing speed
转载自： https://draveness.me/golang-array-and-slice

第 10 页（共 13 页）
Go语言内置运行时（就是runtime），抛弃了传统的内存分配方式，改为自主管理。这样可以自主地实现更好的内存使用模式，比如内存池、预分配等等。这样，不会每次内存分配都需要进行系统调用。

Golang运行时的内存分配算法主要源自 Google 为 C 语言开发的TCMalloc算法，全称Thread-Caching Malloc。核心思想就是把内存分为多级管理，从而降低锁的粒度。它将可用的堆内存采用二级分配的方式进行管理：每个线程都会自行维护一个独立的内存池，进行内存分配时优先从该内存池中分配，当内存池不足时才会向全局内存池申请，以避免不同线程对全局内存池的频繁竞争。

基础概念

Go在程序启动的时候，会先向操作系统申请一块内存（注意这时还只是一段虚拟的地址空间，并不会真正地分配内存），切成小块后自己进行管理。

申请到的内存块被分配了三个区域，在X64上分别是512MB，16GB，512GB大小。

Golang内存分配图

arena区域就是我们所谓的堆区，Go动态分配的内存都是在这个区域，它把内存分割成8KB大小的页，一些页组合起来称为mspan。

bitmap区域标识arena区域哪些地址保存了对象，并且用4bit标志位表示对象是否包含指针、GC标记信息。bitmap中一个byte大小的内存对应arena区域中4个指针大小（指针大小为 8B ）的内存，所以bitmap区域的大小是512GB/(4*8B)=16GB。

Golang内存分配图

Golang内存分配图

从上图其实还可以看到bitmap的高地址部分指向arena区域的低地址部分，也就是说bitmap的地址是由高地址向低地址增长的。

spans区域存放mspan（也就是一些arena分割的页组合起来的内存管理基本单元，后文会再讲）的指针，每个指针对应一页，所以spans区域的大小就是512GB/8KB*8B=512MB。除以8KB是计算arena区域的页数，而最后乘以8是计算spans区域所有指针的大小。创建mspan的时候，按页填充对应的spans区域，在回收object时，根据地址很容易就能找到它所属的mspan。

内存管理单元

mspan：Go中内存管理的基本单元，是由一片连续的8KB的页组成的大块内存。注意，这里的页和操作系统本身的页并不是一回事，它一般是操作系统页大小的几倍。一句话概括：mspan是一个包含起始地址、mspan规格、页的数量等内容的双端链表。
每个mspan按照它自身的属性Size Class的大小分割成若干个object，每个object可存储一个对象。并且会使用一个位图来标记其尚未使用的object。属性Size Class决定object大小，而mspan只会分配给和object尺寸大小接近的对象，当然，对象的大小要小于object大小。还有一个概念：Span Class，它和Size Class的含义差不多，

Size_Class = Span_Class / 2
这是因为其实每个Size Class有两个mspan，也就是有两个Span Class。其中一个分配给含有指针的对象，另一个分配给不含有指针的对象。这会给垃圾回收机制带来利好，之后的文章再谈。

如下图，mspan由一组连续的页组成，按照一定大小划分成object。



Go1.9.2里mspan的Size Class共有67种，每种mspan分割的object大小是8*2n的倍数，这个是写死在代码里的：

// path: /usr/local/go/src/runtime/sizeclasses.go

const _NumSizeClasses = 67

var class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536,1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768}
根据mspan的Size Class可以得到它划分的object大小。 比如Size Class等于3，object大小就是32B。 32B大小的object可以存储对象大小范围在17B~32B的对象。而对于微小对象（小于16B），分配器会将其进行合并，将几个对象分配到同一个object中。

数组里最大的数是32768，也就是32KB，超过此大小就是大对象了，它会被特别对待，这个稍后会再介绍。顺便提一句，类型Size Class为0表示大对象，它实际上直接由堆内存分配，而小对象都要通过mspan来分配。

对于mspan来说，它的Size Class会决定它所能分到的页数，这也是写死在代码里的：

// path: /usr/local/go/src/runtime/sizeclasses.go

const _NumSizeClasses = 67

var class_to_allocnpages = [_NumSizeClasses]uint8{0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 3, 2, 3, 1, 3, 2, 3, 4, 5, 6, 1, 7, 6, 5, 4, 3, 5, 7, 2, 9, 7, 5, 8, 3, 10, 7, 4}
比如当我们要申请一个object大小为32B的mspan的时候，在class_to_size里对应的索引是3，而索引3在class_to_allocnpages数组里对应的页数就是1。

mspan结构体定义：

// path: /usr/local/go/src/runtime/mheap.go

type mspan struct {
    //链表前向指针，用于将span链接起来
    next *mspan 

    //链表前向指针，用于将span链接起来
    prev *mspan 

    // 起始地址，也即所管理页的地址
    startAddr uintptr 

    // 管理的页数
    npages uintptr 

    // 块个数，表示有多少个块可供分配
    nelems uintptr 

    //分配位图，每一位代表一个块是否已分配
    allocBits *gcBits 

    // 已分配块的个数
    allocCount uint16 

    // class表中的class ID，和Size Classs相关
    spanclass spanClass  

    // class表中的对象大小，也即块大小
    elemsize uintptr 
}
我们将mspan放到更大的视角来看：



上图可以看到有两个S指向了同一个mspan，因为这两个S指向的P是同属一个mspan的。所以，通过arena上的地址可以快速找到指向它的S，通过S就能找到mspan，回忆一下前面我们说的mspan区域的每个指针对应一页。

假设最左边第一个mspan的Size Class等于10，根据前面的class_to_size数组，得出这个msapn分割的object大小是144B，算出可分配的对象个数是8KB/144B=56.89个，取整56个，所以会有一些内存浪费掉了，Go的源码里有所有Size Class的mspan浪费的内存的大小；再根据class_to_allocnpages数组，得到这个mspan只由1个page组成；假设这个mspan是分配给无指针对象的，那么spanClass等于20。

startAddr直接指向arena区域的某个位置，表示这个mspan的起始地址，allocBits指向一个位图，每位代表一个块是否被分配了对象；allocCount则表示总共已分配的对象个数。

这样，左起第一个mspan的各个字段参数就如下图所示：



内存管理组件

内存分配由内存分配器完成。分配器由3种组件构成：mcache, mcentral, mheap。

mcache

mcache：每个工作线程都会绑定一个mcache，本地缓存可用的mspan资源，这样就可以直接给Goroutine分配，因为不存在多个Goroutine竞争的情况，所以不会消耗锁资源。

mcache的结构体定义：

//path: /usr/local/go/src/runtime/mcache.go

type mcache struct {
    alloc [numSpanClasses]*mspan
}

numSpanClasses = _NumSizeClasses << 1
mcache用Span Classes作为索引管理多个用于分配的mspan，它包含所有规格的mspan。它是_NumSizeClasses的2倍，也就是67*2=134，为什么有一个两倍的关系，前面我们提到过：为了加速之后内存回收的速度，数组里一半的mspan中分配的对象不包含指针，另一半则包含指针。

对于无指针对象的mspan在进行垃圾回收的时候无需进一步扫描它是否引用了其他活跃的对象。 后面的垃圾回收文章会再讲到，这次先到这里。



mcache在初始化的时候是没有任何mspan资源的，在使用过程中会动态地从mcentral申请，之后会缓存下来。当对象小于等于32KB大小时，使用mcache的相应规格的mspan进行分配。

mcentral

mcentral：为所有mcache提供切分好的mspan资源。每个central保存一种特定大小的全局mspan列表，包括已分配出去的和未分配出去的。 每个mcentral对应一种mspan，而mspan的种类导致它分割的object大小不同。当工作线程的mcache中没有合适（也就是特定大小的）的mspan时就会从mcentral获取。

mcentral被所有的工作线程共同享有，存在多个Goroutine竞争的情况，因此会消耗锁资源。结构体定义：

//path: /usr/local/go/src/runtime/mcentral.go

type mcentral struct {
    // 互斥锁
    lock mutex 

    // 规格
    sizeclass int32 

    // 尚有空闲object的mspan链表
    nonempty mSpanList 

    // 没有空闲object的mspan链表，或者是已被mcache取走的msapn链表
    empty mSpanList 

    // 已累计分配的对象个数
    nmalloc uint64 
}


empty表示这条链表里的mspan都被分配了object，或者是已经被cache取走了的mspan，这个mspan就被那个工作线程独占了。而nonempty则表示有空闲对象的mspan列表。每个central结构体都在mheap中维护。

简单说下mcache从mcentral获取和归还mspan的流程：

获取
加锁；从nonempty链表找到一个可用的mspan；并将其从nonempty链表删除；将取出的mspan加入到empty链表；将mspan返回给工作线程；解锁。

归还
加锁；将mspan从empty链表删除；将mspan加入到nonempty链表；解锁。

mheap

mheap：代表Go程序持有的所有堆空间，Go程序使用一个mheap的全局对象_mheap来管理堆内存。

当mcentral没有空闲的mspan时，会向mheap申请。而mheap没有资源时，会向操作系统申请新内存。mheap主要用于大对象的内存分配，以及管理未切割的mspan，用于给mcentral切割成小对象。

同时我们也看到，mheap中含有所有规格的mcentral，所以，当一个mcache从mcentral申请mspan时，只需要在独立的mcentral中使用锁，并不会影响申请其他规格的mspan。

mheap结构体定义：

//path: /usr/local/go/src/runtime/mheap.go

type mheap struct {
    lock mutex

    // spans: 指向mspans区域，用于映射mspan和page的关系
    spans []*mspan 

    // 指向bitmap首地址，bitmap是从高地址向低地址增长的
    bitmap uintptr 

    // 指示arena区首地址
    arena_start uintptr 

    // 指示arena区已使用地址位置
    arena_used  uintptr 

    // 指示arena区末地址
    arena_end   uintptr 

    central [67*2]struct {
        mcentral mcentral
        pad [sys.CacheLineSize - unsafe.Sizeof(mcentral{})%sys.CacheLineSize]byte
    }
}


上图我们看到，bitmap和arena_start指向了同一个地址，这是因为bitmap的地址是从高到低增长的，所以他们指向的内存位置相同。

内存分配流程

上一篇文章《Golang之变量去哪儿》中我们提到了，变量是在栈上分配还是在堆上分配，是由逃逸分析的结果决定的。通常情况下，编译器是倾向于将变量分配到栈上的，因为它的开销小，最极端的就是”zero garbage”，所有的变量都会在栈上分配，这样就不会存在内存碎片，垃圾回收之类的东西。

Go的内存分配器在分配对象时，根据对象的大小，分成三类：小对象（小于等于16B）、一般对象（大于16B，小于等于32KB）、大对象（大于32KB）。

大体上的分配流程：

32KB 的对象，直接从mheap上分配；
<=16B 的对象使用mcache的tiny分配器分配；
(16B,32KB] 的对象，首先计算对象的规格大小，然后使用mcache中相应规格大小的mspan分配；
如果mcache没有相应规格大小的mspan，则向mcentral申请
如果mcentral没有相应规格大小的mspan，则向mheap申请
如果mheap中也没有合适大小的mspan，则向操作系统申请
总结

Go语言的内存分配非常复杂，它的一个原则就是能复用的一定要复用。源码很难追，后面可能会再来一篇关于内存分配的源码阅读相关的文章。简单总结一下本文吧。

文章从一个比较粗的角度来看Go的内存分配，并没有深入细节。一般而言，了解它的原理，到这个程度也可以了。

Go在程序启动时，会向操作系统申请一大块内存，之后自行管理。
Go内存管理的基本单元是mspan，它由若干个页组成，每种mspan可以分配特定大小的object。
mcache, mcentral, mheap是Go内存管理的三大组件，层层递进。mcache管理线程在本地缓存的mspan；mcentral管理全局的mspan供所有线程使用；mheap管理Go的所有动态分配内存。
极小对象会分配在一个object中，以节省资源，使用tiny分配器分配内存；一般小对象通过mspan分配内存；大对象则直接由mheap分配内存。
参考资料

【简单易懂，非常清晰】https://yq.aliyun.com/articles/652551
【内存分配器的初始化过程，分配流程图很详细】https://www.jianshu.com/p/47691d870756
【全局的图】https://swanspouse.github.io/2018/08/22/golang-memory-model/
【雨痕 Go1.5源码阅读】https://github.com/qyuhen/book
【图不错】https://www.jianshu.com/p/47691d870756
【整体感】https://juejin.im/post/59f2e19f5188253d6816d504
【源码解读】http://legendtkl.com/2017/04/02/golang-alloc/
【重点推荐 深入到晶体管了 图很好】https://www.linuxzen.com/go-memory-allocator-visual-guide.html
【总体描述对象分配流程】http://gocode.cc/project/4/article/103?
【实际Linux命令】https://mikespook.com/2014/12/%E7%90%86%E8%A7%A3-go-%E8%AF%AD%E8%A8%80%E7%9A%84%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8/
【整体流程图 对象分配函数调用链路】http://blog.newbmiao.com/2018/08/20/go-source-analysis-of-memory-alloc.html
【源码讲解 非常细致】https://www.cnblogs.com/zkweb/p/7880099.html
【源码阅读】https://zhuanlan.zhihu.com/p/34930748
原文地址： http://www.cnblogs.com/qcrao-2018/p/10520785.html

第 11 页（共 13 页）
从事服务端开发，少不了要接触网络编程。epoll 作为 Linux 下高性能网络服务器的必备技术至关重要，nginx、Redis、Skynet 和大部分游戏服务器都使用到这一多路复用技术。

epoll 很重要，但是 epoll 与 select 的区别是什么呢？epoll 高效的原因是什么？

网上虽然也有不少讲解 epoll 的文章，但要么是过于浅显，或者陷入源码解析，很少能有通俗易懂的。笔者于是决定编写此文，让缺乏专业背景知识的读者也能够明白 epoll 的原理。

文章核心思想是：要让读者清晰明白 epoll 为什么性能好。

本文会从网卡接收数据的流程讲起，串联起 CPU 中断、操作系统进程调度等知识；再一步步分析阻塞接收数据、select 到 epoll 的进化过程；最后探究 epoll 的实现细节。



一、从网卡接收数据说起

下边是一个典型的计算机结构图，计算机由 CPU、存储器（内存）与网络接口等部件组成，了解 epoll 本质的第一步，要从硬件的角度看计算机怎样接收网络数据。

计算机结构图（图片来源：Linux内核完全注释之微型计算机组成结构）

下图展示了网卡接收数据的过程。

在 ① 阶段，网卡收到网线传来的数据；
经过 ② 阶段的硬件电路的传输；
最终 ③ 阶段将数据写入到内存中的某个地址上。
这个过程涉及到 DMA 传输、IO 通路选择等硬件有关的知识，但我们只需知道：网卡会把接收到的数据写入内存。

网卡接收数据的过程

通过硬件传输，网卡接收的数据存放到内存中，操作系统就可以去读取它们。

二、如何知道接收了数据？

了解 epoll 本质的第二步，要从 CPU 的角度来看数据接收。理解这个问题，要先了解一个概念——中断。

计算机执行程序时，会有优先级的需求。比如，当计算机收到断电信号时，它应立即去保存数据，保存数据的程序具有较高的优先级（电容可以保存少许电量，供 CPU 运行很短的一小段时间）。

一般而言，由硬件产生的信号需要 CPU 立马做出回应，不然数据可能就丢失了，所以它的优先级很高。CPU 理应中断掉正在执行的程序，去做出响应；当 CPU 完成对硬件的响应后，再重新执行用户程序。中断的过程如下图，它和函数调用差不多，只不过函数调用是事先定好位置，而中断的位置由“信号”决定。

中断程序调用

以键盘为例，当用户按下键盘某个按键时，键盘会给 CPU 的中断引脚发出一个高电平，CPU 能够捕获这个信号，然后执行键盘中断程序。下图展示了各种硬件通过中断与 CPU 交互的过程。

CPU 中断（图片来源：net.pku.edu.cn）

现在可以回答“如何知道接收了数据？”这个问题了：当网卡把数据写入到内存后，网卡向 CPU 发出一个中断信号，操作系统便能得知有新数据到来，再通过网卡中断程序去处理数据。

三、进程阻塞为什么不占用 CPU 资源？

了解 epoll 本质的第三步，要从操作系统进程调度的角度来看数据接收。阻塞是进程调度的关键一环，指的是进程在等待某事件（如接收到网络数据）发生之前的等待状态，recv、select 和 epoll 都是阻塞方法。下边分析一下进程阻塞为什么不占用 CPU 资源？

为简单起见，我们从普通的 recv 接收开始分析，先看看下面代码：

//创建socket
int s = socket(AF_INET, SOCK_STREAM, 0);   
//绑定
bind(s, ...)
//监听
listen(s, ...)
//接受客户端连接
int c = accept(s, ...)
//接收客户端数据
recv(c, ...);
//将数据打印出来
printf(...)
这是一段最基础的网络编程代码，先新建 socket 对象，依次调用 bind、listen 与 accept，最后调用 recv 接收数据。recv 是个阻塞方法，当程序运行到 recv 时，它会一直等待，直到接收到数据才往下执行。

那么阻塞的原理是什么？

工作队列

操作系统为了支持多任务，实现了进程调度的功能，会把进程分为“运行”和“等待”等几种状态。运行状态是进程获得 CPU 使用权，正在执行代码的状态；等待状态是阻塞状态，比如上述程序运行到 recv 时，程序会从运行状态变为等待状态，接收到数据后又变回运行状态。操作系统会分时执行各个运行状态的进程，由于速度很快，看上去就像是同时执行多个任务。

下图的计算机中运行着 A、B 与 C 三个进程，其中进程 A 执行着上述基础网络程序，一开始，这 3 个进程都被操作系统的工作队列所引用，处于运行状态，会分时执行。

工作队列中有 A、B 和 C 三个进程

等待队列

当进程 A 执行到创建 socket 的语句时，操作系统会创建一个由文件系统管理的 socket 对象（如下图）。这个 socket 对象包含了发送缓冲区、接收缓冲区与等待队列等成员。等待队列是个非常重要的结构，它指向所有需要等待该 socket 事件的进程。

创建 socket

当程序执行到 recv 时，操作系统会将进程 A 从工作队列移动到该 socket 的等待队列中（如下图）。由于工作队列只剩下了进程 B 和 C，依据进程调度，CPU 会轮流执行这两个进程的程序，不会执行进程 A 的程序。所以进程 A 被阻塞，不会往下执行代码，也不会占用 CPU 资源。

socket 的等待队列

注：操作系统添加等待队列只是添加了对这个“等待中”进程的引用，以便在接收到数据时获取进程对象、将其唤醒，而非直接将进程管理纳入自己之下。上图为了方便说明，直接将进程挂到等待队列之下。

唤醒进程

当 socket 接收到数据后，操作系统将该 socket 等待队列上的进程重新放回到工作队列，该进程变成运行状态，继续执行代码。同时由于 socket 的接收缓冲区已经有了数据，recv 可以返回接收到的数据。

四、内核接收网络数据全过程

这一步，贯穿网卡、中断与进程调度的知识，叙述阻塞 recv 下，内核接收数据的全过程。

如下图所示，进程在 recv 阻塞期间，计算机收到了对端传送的数据（步骤①），数据经由网卡传送到内存（步骤②），然后网卡通过中断信号通知 CPU 有数据到达，CPU 执行中断程序（步骤③）。

此处的中断程序主要有两项功能，先将网络数据写入到对应 socket 的接收缓冲区里面（步骤④），再唤醒进程 A（步骤⑤），重新将进程 A 放入工作队列中。

内核接收数据全过程

唤醒进程的过程如下图所示：

唤醒进程

以上是内核接收数据全过程，这里我们可能会思考两个问题：

其一，操作系统如何知道网络数据对应于哪个 socket？
其二，如何同时监视多个 socket 的数据？
第一个问题：因为一个 socket 对应着一个端口号，而网络数据包中包含了 ip 和端口的信息，内核可以通过端口号找到对应的 socket。当然，为了提高处理速度，操作系统会维护端口号到 socket 的索引结构，以快速读取。

第二个问题是多路复用的重中之重，也正是本文后半部分的重点。

五、同时监视多个 socket 的简单方法

服务端需要管理多个客户端连接，而 recv 只能监视单个 socket，这种矛盾下，人们开始寻找监视多个 socket 的方法。epoll 的要义就是高效地监视多个 socket。

从历史发展角度看，必然先出现一种不太高效的方法，人们再加以改进，正如 select 之于 epoll。

先理解不太高效的 select，才能够更好地理解 epoll 的本质。

假如能够预先传入一个 socket 列表，如果列表中的 socket 都没有数据，挂起进程，直到有一个 socket 收到数据，唤醒进程。这种方法很直接，也是 select 的设计思想。

为方便理解，我们先复习 select 的用法。在下边的代码中，先准备一个数组 fds，让 fds 存放着所有需要监视的 socket。然后调用 select，如果 fds 中的所有 socket 都没有数据，select 会阻塞，直到有一个 socket 接收到数据，select 返回，唤醒进程。用户可以遍历 fds，通过 FD_ISSET 判断具体哪个 socket 收到数据，然后做出处理。

int s = socket(AF_INET, SOCK_STREAM, 0);  
bind(s, ...);
listen(s, ...);
int fds[] =  存放需要监听的socket;
while(1){
    int n = select(..., fds, ...)
    for(int i=0; i < fds.count; i++){
        if(FD_ISSET(fds[i], ...)){
            //fds[i]的数据处理
        }
    }}
select 的流程

select 的实现思路很直接，假如程序同时监视如下图的 sock1、sock2 和 sock3 三个 socket，那么在调用 select 之后，操作系统把进程 A 分别加入这三个 socket 的等待队列中。

操作系统把进程 A 分别加入这三个 socket 的等待队列中

当任何一个 socket 收到数据后，中断程序将唤起进程。下图展示了 sock2 接收到了数据的处理流程：

注：recv 和 select 的中断回调可以设置成不同的内容。

sock2 接收到了数据，中断程序唤起进程 A

所谓唤起进程，就是将进程从所有的等待队列中移除，加入到工作队列里面，如下图所示：

将进程 A 从所有等待队列中移除，再加入到工作队列里面

经由这些步骤，当进程 A 被唤醒后，它知道至少有一个 socket 接收了数据。程序只需遍历一遍 socket 列表，就可以得到就绪的 socket。

这种简单方式行之有效，在几乎所有操作系统都有对应的实现。

但是简单的方法往往有缺点，主要是：

其一，每次调用 select 都需要将进程加入到所有监视 socket 的等待队列，每次唤醒都需要从每个队列中移除。这里涉及了两次遍历，而且每次都要将整个 fds 列表传递给内核，有一定的开销。正是因为遍历操作开销大，出于效率的考量，才会规定 select 的最大监视数量，默认只能监视 1024 个 socket。

其二，进程被唤醒后，程序并不知道哪些 socket 收到数据，还需要遍历一次。

那么，有没有减少遍历的方法？有没有保存就绪 socket 的方法？这两个问题便是 epoll 技术要解决的。

补充说明： 本节只解释了 select 的一种情形。当程序调用 select 时，内核会先遍历一遍 socket，如果有一个以上的 socket 接收缓冲区有数据，那么 select 直接返回，不会阻塞。这也是为什么 select 的返回值有可能大于 1 的原因之一。如果没有 socket 有数据，进程才会阻塞。

六、epoll 的设计思路

epoll 是在 select 出现 N 多年后才被发明的，是 select 和 poll（poll 和 select 基本一样，有少量改进）的增强版本。epoll 通过以下一些措施来改进效率：

措施一：功能分离

select 低效的原因之一是将“维护等待队列”和“阻塞进程”两个步骤合二为一。如下图所示，每次调用 select 都需要这两步操作，然而大多数应用场景中，需要监视的 socket 相对固定，并不需要每次都修改。epoll 将这两个操作分开，先用 epoll_ctl 维护等待队列，再调用 epoll_wait 阻塞进程。显而易见地，效率就能得到提升。

相比 select，epoll 拆分了功能

为方便理解后续的内容，我们先了解一下 epoll 的用法。如下的代码中，先用 epoll_create 创建一个 epoll 对象 epfd，再通过 epoll_ctl 将需要监视的 socket 添加到 epfd 中，最后调用 epoll_wait 等待数据：

int s = socket(AF_INET, SOCK_STREAM, 0);   
bind(s, ...)
listen(s, ...)

int epfd = epoll_create(...);
epoll_ctl(epfd, ...); //将所有需要监听的socket添加到epfd中

while(1){
    int n = epoll_wait(...)
    for(接收到数据的socket){
        //处理
    }
}
功能分离，使得 epoll 有了优化的可能。

措施二：就绪列表

select 低效的另一个原因在于程序不知道哪些 socket 收到数据，只能一个个遍历。如果内核维护一个“就绪列表”，引用收到数据的 socket，就能避免遍历。如下图所示，计算机共有三个 socket，收到数据的 sock2 和 sock3 被就绪列表 rdlist 所引用。当进程被唤醒后，只要获取 rdlist 的内容，就能够知道哪些 socket 收到数据。

就绪列表示意图

七、epoll 的原理与工作流程

本节会以示例和图表来讲解 epoll 的原理和工作流程。

创建 epoll 对象

如下图所示，当某个进程调用 epoll_create 方法时，内核会创建一个 eventpoll 对象（也就是程序中 epfd 所代表的对象）。eventpoll 对象也是文件系统中的一员，和 socket 一样，它也会有等待队列。

内核创建 eventpoll 对象

创建一个代表该 epoll 的 eventpoll 对象是必须的，因为内核要维护“就绪列表”等数据，“就绪列表”可以作为 eventpoll 的成员。

维护监视列表

创建 epoll 对象后，可以用 epoll_ctl 添加或删除所要监听的 socket。以添加 socket 为例，如下图，如果通过 epoll_ctl 添加 sock1、sock2 和 sock3 的监视，内核会将 eventpoll 添加到这三个 socket 的等待队列中。

添加所要监听的 socket

当 socket 收到数据后，中断程序会操作 eventpoll 对象，而不是直接操作进程。

接收数据

当 socket 收到数据后，中断程序会给 eventpoll 的“就绪列表”添加 socket 引用。如下图展示的是 sock2 和 sock3 收到数据后，中断程序让 rdlist 引用这两个 socket。

给就绪列表添加引用

eventpoll 对象相当于 socket 和进程之间的中介，socket 的数据接收并不直接影响进程，而是通过改变 eventpoll 的就绪列表来改变进程状态。

当程序执行到 epoll_wait 时，如果 rdlist 已经引用了 socket，那么 epoll_wait 直接返回，如果 rdlist 为空，阻塞进程。

阻塞和唤醒进程

假设计算机中正在运行进程 A 和进程 B，在某时刻进程 A 运行到了 epoll_wait 语句。如下图所示，内核会将进程 A 放入 eventpoll 的等待队列中，阻塞进程。

epoll_wait 阻塞进程

当 socket 接收到数据，中断程序一方面修改 rdlist，另一方面唤醒 eventpoll 等待队列中的进程，进程 A 再次进入运行状态（如下图）。也因为 rdlist 的存在，进程 A 可以知道哪些 socket 发生了变化。

epoll 唤醒进程

八、epoll 的实现细节

至此，相信读者对 epoll 的本质已经有一定的了解。但我们还需要知道 eventpoll 的数据结构是什么样子？

此外，就绪队列应该应使用什么数据结构？eventpoll 应使用什么数据结构来管理通过 epoll_ctl 添加或删除的 socket？

如下图所示，eventpoll 包含了 lock、mtx、wq（等待队列）与 rdlist 等成员，其中 rdlist 和 rbr 是我们所关心的。

epoll 原理示意图，图片来源：《深入理解Nginx：模块开发与架构解析(第二版)》，陶辉

就绪列表的数据结构

就绪列表引用着就绪的 socket，所以它应能够快速的插入数据。

程序可能随时调用 epoll_ctl 添加监视 socket，也可能随时删除。当删除时，若该 socket 已经存放在就绪列表中，它也应该被移除。所以就绪列表应是一种能够快速插入和删除的数据结构。

双向链表就是这样一种数据结构，epoll 使用双向链表来实现就绪队列（对应上图的 rdllist）。

索引结构

既然 epoll 将“维护监视队列”和“进程阻塞”分离，也意味着需要有个数据结构来保存监视的 socket，至少要方便地添加和移除，还要便于搜索，以避免重复添加。红黑树是一种自平衡二叉查找树，搜索、插入和删除时间复杂度都是O(log(N))，效率较好，epoll 使用了红黑树作为索引结构（对应上图的 rbr）。

注：因为操作系统要兼顾多种功能，以及由更多需要保存的数据，rdlist 并非直接引用 socket，而是通过 epitem 间接引用，红黑树的节点也是 epitem 对象。同样，文件系统也并非直接引用着 socket。为方便理解，本文中省略了一些间接结构。

九、小结

epoll 在 select 和 poll 的基础上引入了 eventpoll 作为中间层，使用了先进的数据结构，是一种高效的多路复用技术。这里也以表格形式简单对比一下 select、poll 与 epoll，结束此文。希望读者能有所收获。



原文地址：https://my.oschina.net/editorial-story/blog/3052308?p=2

第 12 页（共 13 页）
为什么需要 HTTPS？

如今，HTTPS 已经渐渐成为主流，很多大型网站都已经全站 HTTPS 化。那么有了 HTTP 后为什么还需要有 HTTPS 呢？——为了解决 HTTP 的不足。

HTTP 的不足之处

通信内容使用明文——内容可能被窃听
不验证通信方的身份——可能遭遇伪装
无法验证报文的完整性——报文有可能已遭篡改
怎样解决 HTTP 的不足之处？

（一）解决内容为明文问题——加密

公开密钥加密

公开密钥加密（Public-key cryptography） 是一种具备以下特征的加密方式：

使用公开的加密算法
秘钥是保密的
使用密钥来进行加密和解密
也就意味着任何人只要得到了密钥，就能进行密钥。秘钥如果泄漏，加密就失去了意义。

公开密钥加密分为对称密钥加密和非对称密钥加密：

对称秘钥加密

加密和解密双方使用同一个密钥的方式叫做对称密钥加密。这种方式最大的问题是怎样把密钥安全的从一方发送给另一方，由于网络本身就是不安全的，因此无法保证密钥在发送过程中不会被人截获，任何人只要获得了密钥就能随便解密了。当然也可以不通过网络来发送，比如在线下用 U 盘拷给别人，或者口头告诉别人，在某些场景下这种方式是可以的，但是对于 HTTP 网络请求就无能为力了。

非对称秘钥加密

非对称密钥加密解决了密钥在网络上发送的安全问题。非对称秘钥加密使用一对秘钥，一把叫做私有秘钥（private key），另一把叫做公开秘钥（public key）。私钥不能让其他任何人知道，而公钥可以随意发布，任何人都能获得。

私钥只保管在解密的一方，公钥会被发送给加密的一方。使用这种方式时，发送密文的一方会使用对方公开的公钥对数据进行加密，对方收到加密数据后，再使用自己的私钥进行解密。由于能解密的只有私钥，而私钥不用再网络上发送，因此不用担心被盗走。

另外，非对称秘钥加密中，攻击者得到了公钥和密文，想破解出原文，就目前的技术来看是非常困难的，因此也保证了数据的安全。

（二）解决报文完整性问题——数字签名

数字签名是用来确保数据完整性的技术，它可以证明数据是来自谁，证明数据是否未被篡改过。

数字签名是附加在数据上的一段特殊的加密过的校验码，使用数字签名有以下几个好处：

数字签名可以证明数据的作者是谁。因为数字签名是由数据作者用只有作者本人才知道的私钥生成的校验和，因此，这些校验和就像来自于作者的个人“签名”一样。

数字签名可以防止数据被篡改。如果数据被篡改过，校验和就不匹配了。由于校验和只有作者的保密的私钥才能产生，攻击者在没有私钥的情况下，以目前的技术还无法为篡改后的数据伪造出正确的校验和。

下面看一下数字签名在网络数据传输中的一个应用流程：

假设有节点 A 要向节点 B 发送一段报文：

节点A为要发送的报文生成摘要（例如md5）
节点A用自己的私钥对摘要执行签名函数生成数字签名
节点A把数字签名附在要发送的报文之后，然后把报文和签名一块发送给节点B
节点B收到报文后，先取出数字签名部分，用公钥对签名执行反签名函数得到摘要
节点B对报文部分生成摘要（例如md5）
节点B对 4、5 两个步骤得到的两个摘要进行比较
如果一致，则可以认为报文是未被篡改过的
（三）解决通信对方可能被伪装的问题——认证

有了数字签名，就可以验证数据的来源和完整性了，但是仅有数字签名还是有漏洞。使用数字签名进行加密数据传输，数据接收方必须有一个公钥，如果这个公钥被篡改为了攻击者的公钥，那攻击者就可以用自己的私钥发送篡改后的数据了。

为了保证公钥的真实性，引入了认证这一手段。

数字证书

数字证书，有点像生活中的身份证、护照等，是由一个官方的证书颁发机构签发的一组数据。这种证书很难伪造，用于使用者的身份证明。

数字证书包含以下内容：

证书格式版本号
证书序列号
过期时间
证书办法机构
证书使用的签名算法
过期时间
对象名称（人、服务器、组织、公司等）
对象的公开密钥
其它扩展信息
=====================
附上证书颁发机构的数字签名
证书对服务器进行认证：

对服务器进行认证时，数字证书中的 对象名称 字段就是服务器的名称和主机名，对象的公开密钥 字段就是服务器的公开密钥。

客户端或浏览器与服务器通信时会进行如下流程：

建立 SSL 连接时，服务器会把自己的数字证书下发给客户端/浏览器
客户端/浏览器通过证书中 证书颁发机构的数字签名 来验证证书的来源和完整性。一般客户端/浏览器会内置一个受信任的证书颁发机构列表。
一旦证书被认证通过，客户端/浏览器就从证书中取出 对象的公开密钥，用这个公钥来加密数据和服务端进行通信了。
HTTPS = HTTP + 加密 + 数字签名 + 认证

现在来看看 HTTPS 到底是个啥。

HTTPS = HTTP + SSL

SSL（Secure Sockets Layer，安全套接层），诞生于上世纪 90 年代的网景公司，后来又出现了 SSL 的改进版 TLS（Transport Layer Security，传输层安全协议）。所以目前主要用的是 TLS，不过习惯上还是统一叫做 SSL。SSL 主要内容就是加密、数字签名和认证机制，所以：

SSL = 加密 + 数字签名 + 认证

因此：HTTPS = HTTP + 加密 + 数字签名 + 认证

SSL 的加密机制

上面说过了对称秘钥加密和非对称秘钥加密，SSL 的加密是把这两种加密方式混合起来用的。

由于非对称秘钥加密的性能比对称秘钥加密要慢，只有在建立 SSL 安全连接时，使用非对称秘钥加密，在 SSL 安全连接建立成功后，这时已经能保证通信线路上的数据不会被窃取了，后面都会使用对称秘钥加密。

建立 SSL 安全连接前：

建立 SSL 安全连接后：

SSL 的数字签名机制

SSL 的数字签名和上面说到的数字签名基本一致。就是先通过报文得到摘要，把摘要用自己这边的密钥加密后得到数字签名，对方收到后，取出数字签名用自己的密钥反签名后得到摘要，和通过报文得到的摘要进行比对，如果一致的话就代表验证通过了完整性。

SSL 的认证技术

作为服务端想使用 HTTPS，会去官方的正规的证书颁发机构申请证书，需要花点费用。然后服务端会把自己的公钥放在证书里发给服务端，用证书来保证公钥的来源是真实可信的。

一次完整的 HTTPS 的通信步骤

步骤 1：客户端向服务器发送 ClientHello 报文，请求建立 SSL 连接。

ClientHello 报文：

客户端支持的 SSL 版本
客户端支持的加密算法
客户端支持的密钥长度
步骤 2：服务器收到客户端的请求后，向客户端发送 ServerHello 报文。

ServerHello 报文：

决定使用的 SSL 版本
决定使用的加密算法
步骤 3：服务器继续发送 Certificate 报文，即服务器的数字证书，其中包含服务器的公开密钥。

步骤 4：服务器发送 ServerHelloDone 报文，通知客户端进最初阶段的 SSL 握手协商部分结束。

步骤 5：客户端收到以上所有信息后，发送 ClientKeyExchange 报文作为回应。该报文已使用步骤 3 中的公开密钥加密。其中包含一种称为 Pre-master secret 的随机密码串，用于之后的对称秘钥加密通信。

步骤 6：客户端继续发送 ChangeCipherSpec 报文，该报文告诉服务器，在此之后的通信都会采用步骤 5 中的 Pre-master secret 秘钥加密。

步骤 7：客户端发送 Finished 报文。改报文包含连接至今全部报文的整体校验值。

步骤 8：服务端对客户端报文校验后，同样发送 ChangeCipherSpec 报文，含义与步骤 6 中的相同。

步骤 9：服务端发送 Finished 报文。

步骤 10：服务端和客户端的 Finished 报文交换完毕后，SSL 连接建立完成。从此后开始进行应用层协议的通信，即 HTTP 通信。

步骤 11：HTTP 通信。

步骤 12：客户端发送 close_notify 报文请求断开连接。之后再发送 TCP FIN 报文来关闭 TCP 通信。

HTTPS 性能考虑

从上面的步骤可见，一次 HTTPS 连接会比一次单纯的 HTTP 连接做很多额外的事情。因此 HTTPS 的性能开销是比 HTTP 大很多的。考虑到性能这一块，可以在某些对安全要求比较高的场景使用 HTTPS，比如涉及到钱和支付，在一些对安全要求并不高的场景使用性能更好的 HTTP。

随着科技的进步，机器的性能越来越好，人们对安全的需求会比性能更加重要，因此安全的 HTTPS 会渐渐的代替 HTTP。

参考资料

《图解 HTTP》
《HTTP 权威指南》
第 13 页（共 13 页）
// src/runtime/chan.go
func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool {
    if c == nil {
        // 不能往一个nil的channel里写数据
        if !block {
            // 不阻塞就直接返回吧
            return false
        }
        // 阻塞当前g，将当前g与m脱离
        gopark(nil, nil, "chan send (nil chan)", traceEvGoStop, 2)
        throw("unreachable")
    }

    // ...

    if !block && c.closed == 0 && ((c.dataqsiz == 0 && c.recvq.first == nil) ||
        (c.dataqsiz > 0 && c.qcount == c.dataqsiz)) {
        return false
    }

    var t0 int64
    if blockprofilerate > 0 {
        t0 = cputicks()
    }

    // 加锁
    lock(&c.lock)

    // 不能给已关闭的channel发送数据
    if c.closed != 0 {
        unlock(&c.lock)
        panic(plainError("send on closed channel"))
    }

    // 有别的g被阻塞着在等待，唤醒它，赶紧喂它，然后返回成功
    // 所以使用无buffer channel时，必须要先启动进行读channel操作，否则就会出现死锁问题
    if sg := c.recvq.dequeue(); sg != nil {
        send(c, sg, ep, func() { unlock(&c.lock) }, 3)
        return true
    }

    // buffer channel 还有位置，那就把数据放到buffer里
    if c.qcount < c.dataqsiz {
        // 通过指针运算，找到应该插入buf的位置
        qp := chanbuf(c, c.sendx)
        if raceenabled {
            raceacquire(qp)
            racerelease(qp)
        }
        // 然后将发送的数据，拷贝到buf对应位置上。所以对于不论对于指针或非指针，都是值拷贝
        typedmemmove(c.elemtype, qp, ep)
        // 计算好下次插入的位置。底层是循环数组，要注意掉头
        c.sendx++
        if c.sendx == c.dataqsiz {
            c.sendx = 0
        }
        // 记录循环数组元素总数
        c.qcount++
        // 解锁
        unlock(&c.lock)
        // 返回成功
        return true
    }

    // 发送不了，也不阻塞，就返回失败吧
    if !block {
        unlock(&c.lock)
        return false
    }

    // buf里没有空间了，阻塞自己吧。把g自己放进channel的链表里等待投喂。然后gopark挂起自己这个g
    gp := getg()
    mysg := acquireSudog()
    mysg.releasetime = 0
    if t0 != 0 {
        mysg.releasetime = -1
    }
    mysg.elem = ep
    mysg.waitlink = nil
    mysg.g = gp
    mysg.selectdone = nil
    mysg.c = c
    gp.waiting = mysg
    gp.param = nil
    c.sendq.enqueue(mysg)
    goparkunlock(&c.lock, "chan send", traceEvGoBlockSend, 3)

    if mysg != gp.waiting {
        throw("G waiting list is corrupted")
    }
    gp.waiting = nil
    if gp.param == nil {
        if c.closed == 0 {
            throw("chansend: spurious wakeup")
        }
        panic(plainError("send on closed channel"))
    }
    gp.param = nil
    if mysg.releasetime > 0 {
        blockevent(mysg.releasetime-t0, 2)
    }
    mysg.c = nil
    releaseSudog(mysg)
    return true
}

func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) {
    if raceenabled {
        if c.dataqsiz == 0 {
            racesync(c, sg)
        } else {
            qp := chanbuf(c, c.recvx)
            raceacquire(qp)
            racerelease(qp)
            raceacquireg(sg.g, qp)
            racereleaseg(sg.g, qp)
            c.recvx++
            if c.recvx == c.dataqsiz {
                c.recvx = 0
            }
            c.sendx = c.recvx // c.sendx = (c.sendx+1) % c.dataqsiz
        }
    }
    if sg.elem != nil {
        sendDirect(c.elemtype, sg, ep)
        sg.elem = nil
    }
    gp := sg.g
    unlockf()
    gp.param = unsafe.Pointer(sg)
    if sg.releasetime != 0 {
        sg.releasetime = cputicks()
    }
    // 把gp这个g放在p的runnext下，等待调度
    goready(gp, skip+1)
}
func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // ... if c == nil { if !block { return } gopark(nil, nil, "chan receive (nil chan)", traceEvGoStop, 2) throw("unreachable") } if !block && (c.dataqsiz == 0 && c.sendq.first == nil || c.dataqsiz > 0 && atomic.Loaduint(&c.qcount) == 0) && atomic.Load(&c.closed) == 0 { return } var t0 int64 if blockprofilerate > 0 { t0 = cputicks() } // 加锁 lock(&c.lock) // close 了的channel还能读的 if c.closed != 0 && c.qcount == 0 { if raceenabled { raceacquire(unsafe.Pointer(c)) } unlock(&c.lock) if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } // 有别的g被阻塞着，唤醒它，让它发送数据 if sg := c.sendq.dequeue(); sg != nil { recv(c, sg, ep, func() { unlock(&c.lock) }, 3) return true, true } // qcount>0，说明这是个buffer channel，并且buffer里有数据 // 那就读出来返回 if c.qcount > 0 { // Receive directly from queue qp := chanbuf(c, c.recvx) if raceenabled { raceacquire(qp) racerelease(qp) } if ep != nil { typedmemmove(c.elemtype, ep, qp) } typedmemclr(c.elemtype, qp) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.qcount-- unlock(&c.lock) return true, true } if !block { unlock(&c.lock) return false, false } // 无论是buffer还是unbuffer，都没数据读了，只好阻塞自己，加到chan的链表里了 gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.selectdone = nil mysg.c = c gp.param = nil c.recvq.enqueue(mysg) goparkunlock(&c.lock, "chan receive", traceEvGoBlockRecv, 3) if mysg != gp.waiting { throw("G waiting list is corrupted") } gp.waiting = nil if mysg.releasetime > 0 { blockevent(mysg.releasetime-t0, 2) } closed := gp.param == nil gp.param = nil mysg.c = nil releaseSudog(mysg) return true, !closed } func recv(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { // unbuffer channel if c.dataqsiz == 0 { if raceenabled { racesync(c, sg) } if ep != nil { // 直接从g上把数据拷贝到ep的位置上 recvDirect(c.elemtype, sg, ep) } } else { // buffer里有数据，把buffer里的读出来 // buffer channel // buf里有数据，把它读出来 qp := chanbuf(c, c.recvx) if raceenabled { raceacquire(qp) racerelease(qp) raceacquireg(sg.g, qp) racereleaseg(sg.g, qp) } if ep != nil { // 读出来的数据要写到ep对应的地址上 typedmemmove(c.elemtype, ep, qp) } // copy data from sender to queue // 然后再将被阻塞写的g的数据到buffer里 // 然后再把阻塞着的g它对应的数据，放到上面buf空出来的位置上 typedmemmove(c.elemtype, qp, sg.elem) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.sendx = c.recvx // c.sendx = (c.sendx+1) % c.dataqsiz } sg.elem = nil gp := sg.g unlockf() gp.param = unsafe.Pointer(sg) if sg.releasetime != 0 { sg.releasetime = cputicks() } // 好了，被阻塞写的g写完后，唤醒它吧 goready(gp, skip+1) }